{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine Tuning with BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LHYAtRIIwy_4",
        "RVtVRS971PFX",
        "za-IcSKp8vJK"
      ],
      "authorship_tag": "ABX9TyN54Bq6HFo9HJ9gcLUn+NNy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RenYuanXue/LearningBERT/blob/main/Fine_Tuning_with_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHYAtRIIwy_4"
      },
      "source": [
        "## Load CoLA Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d99IYJpixEoX"
      },
      "source": [
        "Get wget package to download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeR11_5Gw1M5",
        "outputId": "fab64aa8-85d1-4b1a-d48b-55bd3a4bb42d"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUMNb6FNxQO1"
      },
      "source": [
        "Download the zip file using wget"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm4bvatVw8hQ",
        "outputId": "e0a2c6c8-a073-4e7b-bad0-34b316916172"
      },
      "source": [
        "import wget\r\n",
        "import os\r\n",
        "\r\n",
        "print('Downloading dataset...')\r\n",
        "\r\n",
        "# The url for the dataset zip file.\r\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\r\n",
        "\r\n",
        "# Download the file (if we haven't already)\r\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\r\n",
        "  wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y73UXqHnyZED"
      },
      "source": [
        "Unzip the dataset to file system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlaHyyC-yb8v"
      },
      "source": [
        "# Unzip the dataset (if we haven't done so).\r\n",
        "if not os.path.exists('./cola_public/'):\r\n",
        "  !unzip cola_public_1.1.zip"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxES8m_YzldW"
      },
      "source": [
        "Load the dataset to pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "pVOjFg88ym-M",
        "outputId": "237f0559-c679-48c2-b974-1b4fe678532a"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "# Load data to pandas dataframe.\r\n",
        "df = pd.read_csv('./cola_public/raw/in_domain_train.tsv',\r\n",
        "          delimiter = '\\t', header = None,\r\n",
        "          names = ['sentence_source', 'label', 'label_notes', 'sentence'])\r\n",
        "\r\n",
        "# Report number of sentences in the dataframe.\r\n",
        "print('Number of training sentences: {0}'.format(df.shape[0]))\r\n",
        "\r\n",
        "# Display first few rows from the data.\r\n",
        "df.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 8551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our friends won't buy this analysis, let alone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One more pseudo generalization and I'm giving up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One more pseudo generalization or I'm giving up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The more we study verbs, the crazier they get.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Day by day the facts are getting murkier.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentence_source  ...                                           sentence\n",
              "0            gj04  ...  Our friends won't buy this analysis, let alone...\n",
              "1            gj04  ...  One more pseudo generalization and I'm giving up.\n",
              "2            gj04  ...   One more pseudo generalization or I'm giving up.\n",
              "3            gj04  ...     The more we study verbs, the crazier they get.\n",
              "4            gj04  ...          Day by day the facts are getting murkier.\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLraAF-c0yo_"
      },
      "source": [
        "If the sentence is grammatically correct, it is labelled as 1, otherwise 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKHZJ-xn1Ci6"
      },
      "source": [
        "Extract the sentences and labels used for BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZdK--Nbz62v"
      },
      "source": [
        "sentences = df.sentence.values\r\n",
        "labels = df.label.values"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVtVRS971PFX"
      },
      "source": [
        "## Tokenization & input formatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QawUCnoU27DU"
      },
      "source": [
        "Get transformers library in case don't have it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YPB1Y7c3EAe",
        "outputId": "28a411a7-f58d-4257-f045-d8dfbbfcbc80"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7pki19Z2twm"
      },
      "source": [
        "First, we need to load the BERT tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fng1CMjx1KtD"
      },
      "source": [
        "from transformers import BertTokenizer\r\n",
        "\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CjxxPCq3LxD"
      },
      "source": [
        "Apply the tokenizer to our input sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyUb0KMO3RWq",
        "outputId": "99c20327-25b2-45c0-af93-89d41b25fe3f"
      },
      "source": [
        "# Print original sentence.\r\n",
        "print('Original: ', sentences[0])\r\n",
        "\r\n",
        "# Print splitted sentences as tokens.\r\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\r\n",
        "\r\n",
        "# Print sentences mapped to token ids.\r\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soiP79AFNWll"
      },
      "source": [
        "Use tokenizer encode function to encode sentences. However, it only takes care of truncating, not padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTgVWRGJ36t-"
      },
      "source": [
        "# Save mapped sentences.\r\n",
        "input_ids = []\r\n",
        "\r\n",
        "# Loop through all sentences.\r\n",
        "for sentence in sentences:\r\n",
        "  # The function encode will:\r\n",
        "  # 1. Map each word to corresponded ids.\r\n",
        "  # 2. Append [SEP] at end of each sentence.\r\n",
        "  # 3. Prepand [CLS] to start of each sentence.\r\n",
        "  # 4. Map tokens to their IDs.\r\n",
        "  encoded_sentence = tokenizer.encode(\r\n",
        "              sentence,\r\n",
        "              add_special_tokens = True # Add [SEP] and [CLS]\r\n",
        "              # max_length = 128, # Truncate all sentences.\r\n",
        "              # return_tensors = 'pt' # Return pytorch tensors.\r\n",
        "            )\r\n",
        "  input_ids.append(encoded_sentence)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmtC6pfWPAfS"
      },
      "source": [
        "Now we need to padding and truncating. Find the maximum sentence length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sVt5vybO5G5",
        "outputId": "95f7b6fa-f534-4250-d5fc-11f38b499219"
      },
      "source": [
        "print('Max sentence length: {0}'.format(max([len(sentence) for sentence in input_ids])))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length: 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57zIfsLNPZXq"
      },
      "source": [
        "Therefore we choose max_length = 64, since 32 < 47 < 64."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGnr-vThPVWc"
      },
      "source": [
        "# Use Keras to do the padding.\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "MAX_LEN = 64\r\n",
        "\r\n",
        "input_ids = pad_sequences(input_ids, maxlen = MAX_LEN, dtype = \"long\",\r\n",
        "              value = 0, truncating = 'post', padding = 'post')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGT2fgOXQHvP"
      },
      "source": [
        "Now, create attention masks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrZnxkkRP4yz"
      },
      "source": [
        "attention_masks = []\r\n",
        "\r\n",
        "for sentence in input_ids:\r\n",
        "  curr_mask = [int(token_id > 0) for token_id in sentence]\r\n",
        "\r\n",
        "  attention_masks.append(curr_mask)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbFTfqvsCIcj"
      },
      "source": [
        "Make train and validation splits using sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXbgGCYLQbg1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "# 90% Train, 10% Validation.\r\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,\r\n",
        "                                            random_state = 2018, test_size = 0.1)\r\n",
        "\r\n",
        "# Do the same for masking.\r\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\r\n",
        "                              random_state = 2018, test_size = 0.1)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaV54KZKDGTH"
      },
      "source": [
        "Now, convert all used inputs to torch tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFNQqulfDCtS"
      },
      "source": [
        "import torch\r\n",
        "\r\n",
        "train_inputs = torch.tensor(train_inputs)\r\n",
        "validation_inputs = torch.tensor(validation_inputs)\r\n",
        "\r\n",
        "train_labels = torch.tensor(train_labels)\r\n",
        "validation_labels = torch.tensor(validation_labels)\r\n",
        "\r\n",
        "train_masks = torch.tensor(train_masks)\r\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdULSfNgDmR1"
      },
      "source": [
        "Lastly, we use torch's DataLoader to make batches of inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnStrhjdDixj"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n",
        "\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# Create DataLoader for training set.\r\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\r\n",
        "train_sampler = RandomSampler(train_data)\r\n",
        "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\r\n",
        "\r\n",
        "# Create DataLoader for validation set.\r\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\r\n",
        "validation_sampler = RandomSampler(validation_data)\r\n",
        "validation_dataloader = DataLoader(validation_data, sampler = validation_sampler, batch_size = batch_size)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za-IcSKp8vJK"
      },
      "source": [
        "## Train Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP6FCXth7oPN",
        "outputId": "3b04b576-1cf4-47d8-92d4-14f56b872ae0"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\r\n",
        "\r\n",
        "# Load the pretrained BERT model with single linear classification layer on top.\r\n",
        "model = BertForSequenceClassification.from_pretrained(\r\n",
        "    \"bert-base-uncased\", # 12 layer BERT model, with an uncased vocab.\r\n",
        "    # num_labels = 2, # Number of output labels = 2, binary classification.\r\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\r\n",
        "    output_hidden_states = False # Whether the model returns all hidden states.\r\n",
        ")\r\n",
        "\r\n",
        "# Let Pytorch to run the model on GPU if available\r\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "print('The model will run on GPU') if torch.cuda.is_available() else print('The model will run on CPU')\r\n",
        "model.to(device)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The model will run on GPU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrr8ndvR_sar"
      },
      "source": [
        "Create optimizer & learing rate scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmT7VAEE9zDf"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\r\n",
        "          lr = 2e-5, # Default is 5e-5.\r\n",
        "          eps = 1e-8 # Default is 1e-8.\r\n",
        "        )"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg7T45D3AOIw"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\r\n",
        "\r\n",
        "# Number of training epochs.\r\n",
        "epochs = 4\r\n",
        "\r\n",
        "# Total number of training steps is number of batches * number of epochs.\r\n",
        "total_steps = len(train_dataloader) * epochs\r\n",
        "\r\n",
        "# Create the learning rate scheduler. The learning rate will decrease as epochs increase.\r\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\r\n",
        "                       num_warmup_steps = 0,\r\n",
        "                       num_training_steps = total_steps)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyKxfN5zAw4p"
      },
      "source": [
        "Helper function 1: calculate accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBwtpKxKAwlS"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "def flat_accuracy(preds, labels):\r\n",
        "  pred_flat = np.argmax(preds, axis = 1).flatten()\r\n",
        "  labels_flat = labels.flatten()\r\n",
        "  return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zwgamDuBWyj"
      },
      "source": [
        "Helper function 2: format elapsed times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFVUEo0wBVkc"
      },
      "source": [
        "import time\r\n",
        "import datetime\r\n",
        "\r\n",
        "def format_time(elapsed):\r\n",
        "  # Round to nearest second.\r\n",
        "  elapsed_rounded = int(round(elapsed))\r\n",
        "\r\n",
        "  # Format as hh:mm:ss.\r\n",
        "  return str(datetime.timedelta(seconds = elapsed_rounded))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajR9pGrDBucw"
      },
      "source": [
        "Set seed value for reproducible results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JX0ZKfWBnJn"
      },
      "source": [
        "import random\r\n",
        "\r\n",
        "# Set seed value for reproducible results.\r\n",
        "seed_num = 42\r\n",
        "\r\n",
        "random.seed(seed_num)\r\n",
        "np.random.seed(seed_num)\r\n",
        "torch.manual_seed(seed_num)\r\n",
        "torch.cuda.manual_seed_all(seed_num)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq-GKiXaCPpP"
      },
      "source": [
        "Main train loop.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPlwqzgMCGMT",
        "outputId": "4ecc3da0-6421-4cb8-98d3-c186ab0280e7"
      },
      "source": [
        "loss_values = []\r\n",
        "training_stats = []\r\n",
        "\r\n",
        "# Measure the total training time for the whole run.\r\n",
        "total_t0 = time.time()\r\n",
        "\r\n",
        "for epoch_i in range(0, epochs):\r\n",
        "\r\n",
        "  # =====================================\r\n",
        "  #       Training\r\n",
        "  # =====================================\r\n",
        "\r\n",
        "  print(\"\")\r\n",
        "  print('====== Epoch {:} / {:} ======'.format(epoch_i + 1, epochs))\r\n",
        "  print('Running Training...')\r\n",
        "\r\n",
        "  t0 = time.time()\r\n",
        "\r\n",
        "  # Reset loss at start of every loop.\r\n",
        "  total_loss = 0\r\n",
        "\r\n",
        "  # This code doesn't train the model automatically.\r\n",
        "  # This code only put model in training mode.\r\n",
        "  # Because 'dropout' and 'batchnorm' layers perform differently during train v.s test.\r\n",
        "  model.train()\r\n",
        "\r\n",
        "  # For each batch in training data...\r\n",
        "  for step, batch in enumerate(train_dataloader):\r\n",
        "  \r\n",
        "    # Progress update every 40 batches.\r\n",
        "    if step % 40 == 0 and not step == 0:\r\n",
        "      # Calculate elapsed time in minutes.\r\n",
        "      elapsed = format_time(time.time() - t0)\r\n",
        "\r\n",
        "      # Report progress.\r\n",
        "      print(' Brach {:<5} of {:>5}, Elapsed:{:}.'.format(step, len(train_dataloader), elapsed))\r\n",
        "\r\n",
        "    # batch contains 3 pytorch tensors:\r\n",
        "    # [0]: input ids.\r\n",
        "    # [1]: attention masks.\r\n",
        "    # [2]: labels.\r\n",
        "    b_input_ids = batch[0].to(device)\r\n",
        "    b_input_mask = batch[1].to(device)\r\n",
        "    b_labels = batch[2].to(device)\r\n",
        "\r\n",
        "    # Always clear previous gradients.\r\n",
        "    # Pytorch doesn't do this automatically,\r\n",
        "    # because in some networks it's helpful to keep previous gradients.\r\n",
        "    model.zero_grad()\r\n",
        "\r\n",
        "    outputs = model(b_input_ids,\r\n",
        "             token_type_ids = None,\r\n",
        "             attention_mask = b_input_mask,\r\n",
        "             labels = b_labels)\r\n",
        "    \r\n",
        "    loss = outputs.loss\r\n",
        "\r\n",
        "    # Accumulate loss values.\r\n",
        "    total_loss += loss.item()\r\n",
        "\r\n",
        "    # Perform a backward pass to calculate gradients.\r\n",
        "    loss.backward()\r\n",
        "\r\n",
        "    # Clip the norm of the gradients to 1.0.\r\n",
        "    # This is to help prevent the \"exploding gradients\" problem.\r\n",
        "    torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\r\n",
        "\r\n",
        "    # Update parameters and take a step using the computed gradients.\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    # Update learning rate.\r\n",
        "    scheduler.step()\r\n",
        "\r\n",
        "  # Calculate the average loss over the training data.\r\n",
        "  avg_train_loss = total_loss / len(train_dataloader)\r\n",
        "\r\n",
        "  # Store the loss value for plotting the learning curve.\r\n",
        "  loss_values.append(avg_train_loss)\r\n",
        "\r\n",
        "  # Measure how long this epoch took.\r\n",
        "  training_time = format_time(time.time() - t0)\r\n",
        "\r\n",
        "  print(\"\")\r\n",
        "  print(\" Average training loss: {0:.2f}\".format(avg_train_loss))\r\n",
        "  print(\" Traing epoch took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "\r\n",
        "  # =====================================\r\n",
        "  #       Validation\r\n",
        "  # =====================================\r\n",
        "\r\n",
        "  print(\"\")\r\n",
        "  print(\"Runing Validation ...\")\r\n",
        "\r\n",
        "  t0 = time.time()\r\n",
        "\r\n",
        "  # Put the model in evaluation mode--the dropout layers behave differently\r\n",
        "  # during evaluation.\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  # Tracking variables \r\n",
        "  total_eval_accuracy = 0\r\n",
        "  total_eval_loss = 0\r\n",
        "  nb_eval_steps = 0\r\n",
        "\r\n",
        "  # Evaluate data for one epoch\r\n",
        "  for batch in validation_dataloader:\r\n",
        "      \r\n",
        "    # Unpack this training batch from our dataloader. \r\n",
        "    #\r\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \r\n",
        "    # the `to` method.\r\n",
        "    #\r\n",
        "    # `batch` contains three pytorch tensors:\r\n",
        "    #   [0]: input ids \r\n",
        "    #   [1]: attention masks\r\n",
        "    #   [2]: labels \r\n",
        "    b_input_ids = batch[0].to(device)\r\n",
        "    b_input_mask = batch[1].to(device)\r\n",
        "    b_labels = batch[2].to(device)\r\n",
        "\r\n",
        "    # Tell pytorch not to bother with constructing the compute graph during\r\n",
        "    # the forward pass, since this is only needed for backprop (training).\r\n",
        "    with torch.no_grad():        \r\n",
        "\r\n",
        "      # Forward pass, calculate logit predictions.\r\n",
        "      # token_type_ids is the same as the \"segment ids\", which \r\n",
        "      # differentiates sentence 1 and 2 in 2-sentence tasks.\r\n",
        "      result = model(b_input_ids, \r\n",
        "              token_type_ids=None, \r\n",
        "              attention_mask=b_input_mask,\r\n",
        "              labels=b_labels,\r\n",
        "              return_dict=True)\r\n",
        "      \r\n",
        "    # Get the loss and \"logits\" output by the model. The \"logits\" are the \r\n",
        "    # output values prior to applying an activation function like the \r\n",
        "    # softmax.\r\n",
        "    loss = result.loss\r\n",
        "    logits = result.logits\r\n",
        "            \r\n",
        "    # Accumulate the validation loss.\r\n",
        "    total_eval_loss += loss.item()\r\n",
        "\r\n",
        "    # Move logits and labels to CPU\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "    label_ids = b_labels.to('cpu').numpy()\r\n",
        "\r\n",
        "    # Calculate the accuracy for this batch of test sentences, and\r\n",
        "    # accumulate it over all batches.\r\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\r\n",
        "\r\n",
        "  # Report the final accuracy for this validation run.\r\n",
        "  avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\r\n",
        "  print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\r\n",
        "\r\n",
        "  # Calculate the average loss over all of the batches.\r\n",
        "  avg_val_loss = total_eval_loss / len(validation_dataloader)\r\n",
        "    \r\n",
        "  # Measure how long the validation run took.\r\n",
        "  validation_time = format_time(time.time() - t0)\r\n",
        "    \r\n",
        "  print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\r\n",
        "  print(\"  Validation took: {:}\".format(validation_time))\r\n",
        "\r\n",
        "  # Record all statistics from this epoch.\r\n",
        "  training_stats.append(\r\n",
        "      {\r\n",
        "        'epoch': epoch_i + 1,\r\n",
        "        'Training Loss': avg_train_loss,\r\n",
        "        'Valid. Loss': avg_val_loss,\r\n",
        "        'Valid. Accur.': avg_val_accuracy,\r\n",
        "        'Training Time': training_time,\r\n",
        "        'Validation Time': validation_time\r\n",
        "      }\r\n",
        "    )\r\n",
        "  \r\n",
        "print(\"\")\r\n",
        "print(\"Training complete!\")\r\n",
        "\r\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "====== Epoch 1 / 4 ======\n",
            "Running Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:66: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Brach 40    of   241, Elapsed:0:00:09.\n",
            " Brach 80    of   241, Elapsed:0:00:17.\n",
            " Brach 120   of   241, Elapsed:0:00:26.\n",
            " Brach 160   of   241, Elapsed:0:00:34.\n",
            " Brach 200   of   241, Elapsed:0:00:43.\n",
            " Brach 240   of   241, Elapsed:0:00:51.\n",
            "\n",
            " Average training loss: 0.51\n",
            " Traing epoch took: 0:00:51\n",
            "\n",
            "Runing Validation ...\n",
            "  Accuracy: 0.77\n",
            "  Validation Loss: 0.53\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "====== Epoch 2 / 4 ======\n",
            "Running Training...\n",
            " Brach 40    of   241, Elapsed:0:00:08.\n",
            " Brach 80    of   241, Elapsed:0:00:17.\n",
            " Brach 120   of   241, Elapsed:0:00:25.\n",
            " Brach 160   of   241, Elapsed:0:00:34.\n",
            " Brach 200   of   241, Elapsed:0:00:42.\n",
            " Brach 240   of   241, Elapsed:0:00:51.\n",
            "\n",
            " Average training loss: 0.32\n",
            " Traing epoch took: 0:00:51\n",
            "\n",
            "Runing Validation ...\n",
            "  Accuracy: 0.82\n",
            "  Validation Loss: 0.47\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "====== Epoch 3 / 4 ======\n",
            "Running Training...\n",
            " Brach 40    of   241, Elapsed:0:00:08.\n",
            " Brach 80    of   241, Elapsed:0:00:17.\n",
            " Brach 120   of   241, Elapsed:0:00:25.\n",
            " Brach 160   of   241, Elapsed:0:00:34.\n",
            " Brach 200   of   241, Elapsed:0:00:42.\n",
            " Brach 240   of   241, Elapsed:0:00:51.\n",
            "\n",
            " Average training loss: 0.20\n",
            " Traing epoch took: 0:00:51\n",
            "\n",
            "Runing Validation ...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.50\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "====== Epoch 4 / 4 ======\n",
            "Running Training...\n",
            " Brach 40    of   241, Elapsed:0:00:08.\n",
            " Brach 80    of   241, Elapsed:0:00:17.\n",
            " Brach 120   of   241, Elapsed:0:00:25.\n",
            " Brach 160   of   241, Elapsed:0:00:34.\n",
            " Brach 200   of   241, Elapsed:0:00:42.\n",
            " Brach 240   of   241, Elapsed:0:00:51.\n",
            "\n",
            " Average training loss: 0.14\n",
            " Traing epoch took: 0:00:51\n",
            "\n",
            "Runing Validation ...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.58\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:03:31 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBI-afVeAfti"
      },
      "source": [
        "Create dataframe from the statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "PiXuJ1SWAbsQ",
        "outputId": "1f24bd55-1eab-41cd-8b7c-d080471a7df9"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "# Display floats with two decimal places.\r\n",
        "pd.set_option('precision', 2)\r\n",
        "\r\n",
        "# Create a DataFrame from our training statistics.\r\n",
        "df_stats = pd.DataFrame(data=training_stats)\r\n",
        "\r\n",
        "# Use the 'epoch' as the row index.\r\n",
        "df_stats = df_stats.set_index('epoch')\r\n",
        "\r\n",
        "# Display the table.\r\n",
        "df_stats"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.51</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0:00:51</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.32</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0:00:51</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:00:51</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.14</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:00:51</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.51         0.53           0.77       0:00:51         0:00:02\n",
              "2               0.32         0.47           0.82       0:00:51         0:00:02\n",
              "3               0.20         0.50           0.83       0:00:51         0:00:02\n",
              "4               0.14         0.58           0.83       0:00:51         0:00:02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY7oMQhjAQ7h"
      },
      "source": [
        "View the training and validation loss in pyplot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "21HVVH13Hgl6",
        "outputId": "e1b88f4b-235c-468a-b20b-22a8898102b4"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "% matplotlib inline\r\n",
        "\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# Use plot styling from seaborn.\r\n",
        "sns.set(style='darkgrid')\r\n",
        "\r\n",
        "# Increase the plot size and font size.\r\n",
        "sns.set(font_scale=1.5)\r\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\r\n",
        "\r\n",
        "# Plot the learning curve.\r\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\r\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\r\n",
        "\r\n",
        "# Label the plot.\r\n",
        "plt.title(\"Training & Validation Loss\")\r\n",
        "plt.xlabel(\"Epoch\")\r\n",
        "plt.ylabel(\"Loss\")\r\n",
        "plt.legend()\r\n",
        "plt.xticks([1, 2, 3, 4])\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkXbVIvKBKpn"
      },
      "source": [
        "## Performance on Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVpLiV59B3I3"
      },
      "source": [
        "Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fUxSyhVAZ_y",
        "outputId": "791fa52f-5864-4f43-8688-141b7f1a8a55"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "# Load the dataset into a pandas dataframe.\r\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\r\n",
        "\r\n",
        "# Report the number of sentences.\r\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\r\n",
        "\r\n",
        "# Create sentence and label lists\r\n",
        "sentences = df.sentence.values\r\n",
        "labels = df.label.values\r\n",
        "\r\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\r\n",
        "input_ids = []\r\n",
        "attention_masks = []\r\n",
        "\r\n",
        "# For every sentence...\r\n",
        "for sent in sentences:\r\n",
        "    # `encode_plus` will:\r\n",
        "    #   (1) Tokenize the sentence.\r\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\r\n",
        "    #   (3) Append the `[SEP]` token to the end.\r\n",
        "    #   (4) Map tokens to their IDs.\r\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\r\n",
        "    #   (6) Create attention masks for [PAD] tokens.\r\n",
        "    encoded_dict = tokenizer.encode_plus(\r\n",
        "                        sent,                      # Sentence to encode.\r\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\r\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\r\n",
        "                        pad_to_max_length = True,\r\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\r\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\r\n",
        "                   )\r\n",
        "    \r\n",
        "    # Add the encoded sentence to the list.    \r\n",
        "    input_ids.append(encoded_dict['input_ids'])\r\n",
        "    \r\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\r\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\r\n",
        "\r\n",
        "# Convert the lists into tensors.\r\n",
        "input_ids = torch.cat(input_ids, dim=0)\r\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\r\n",
        "labels = torch.tensor(labels)\r\n",
        "\r\n",
        "# Set the batch size.  \r\n",
        "batch_size = 32  \r\n",
        "\r\n",
        "# Create the DataLoader.\r\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\r\n",
        "prediction_sampler = SequentialSampler(prediction_data)\r\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cO1wN10ICHBm"
      },
      "source": [
        "Evaluation on test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1ou3TOSCC5o",
        "outputId": "f36fe27b-3fa9-4ad3-899d-10058be0ab0c"
      },
      "source": [
        "# Prediction on test set\r\n",
        "\r\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\r\n",
        "\r\n",
        "# Put model in evaluation mode\r\n",
        "model.eval()\r\n",
        "\r\n",
        "# Tracking variables \r\n",
        "predictions , true_labels = [], []\r\n",
        "\r\n",
        "# Predict \r\n",
        "for batch in prediction_dataloader:\r\n",
        "  # Add batch to GPU\r\n",
        "  batch = tuple(t.to(device) for t in batch)\r\n",
        "  \r\n",
        "  # Unpack the inputs from our dataloader\r\n",
        "  b_input_ids, b_input_mask, b_labels = batch\r\n",
        "  \r\n",
        "  # Telling the model not to compute or store gradients, saving memory and \r\n",
        "  # speeding up prediction\r\n",
        "  with torch.no_grad():\r\n",
        "      # Forward pass, calculate logit predictions.\r\n",
        "      result = model(b_input_ids, \r\n",
        "                     token_type_ids=None, \r\n",
        "                     attention_mask=b_input_mask,\r\n",
        "                     return_dict=True)\r\n",
        "\r\n",
        "  logits = result.logits\r\n",
        "\r\n",
        "  # Move logits and labels to CPU\r\n",
        "  logits = logits.detach().cpu().numpy()\r\n",
        "  label_ids = b_labels.to('cpu').numpy()\r\n",
        "  \r\n",
        "  # Store predictions and true labels\r\n",
        "  predictions.append(logits)\r\n",
        "  true_labels.append(label_ids)\r\n",
        "\r\n",
        "print('    DONE.')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFwS3oiJCNFZ"
      },
      "source": [
        "Accuracy on CoLA benchmark is measured using \"Matthews correlation coefficient\" (MCC), used when classes are imbalanced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR8SLh3rCLCM",
        "outputId": "201ee43a-5f30-4575-a42a-34c050a5a6cc"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWoNP_CaCXCj",
        "outputId": "5adf34a8-48be-41c0-cb1a-09b75ec2efe8"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\r\n",
        "\r\n",
        "matthews_set = []\r\n",
        "\r\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\r\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\r\n",
        "\r\n",
        "# For each input batch...\r\n",
        "for i in range(len(true_labels)):\r\n",
        "  \r\n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \r\n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\r\n",
        "  # in to a list of 0s and 1s.\r\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\r\n",
        "  \r\n",
        "  # Calculate and store the coef for this batch.  \r\n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \r\n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owcEAj5KCfpT"
      },
      "source": [
        "Take a look at the variabilities of MCC between batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "ipkVKHh4CayX",
        "outputId": "fb4c6e53-14fd-434c-8689-ba0665e76c6f"
      },
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\r\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\r\n",
        "\r\n",
        "plt.title('MCC Score per Batch')\r\n",
        "plt.ylabel('MCC Score (-1 to +1)')\r\n",
        "plt.xlabel('Batch #')\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvMAAAGaCAYAAACCFszYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeViVdeL+8fsAB1BQQQMzFTIVcQHc0jTNxI3Kfa8UzdI2mrLLQutXM+M0WeokjcuoLSZkrkCkTq7NtKipmYkmmlK5RCmKoKB4EM7vD78yEXA46Dkcnnq/rqvris+zfO5zMLx5+jzPMVmtVqsAAAAAGI6bqwMAAAAAuD6UeQAAAMCgKPMAAACAQVHmAQAAAIOizAMAAAAGRZkHAAAADIoyDwCAwY0dO1aRkZGujgHABTxcHQAAXGXnzp2Kjo6WJD344IN6+eWXS+1z9uxZ9ejRQwUFBerUqZMSEhJK7bN//34tW7ZMu3fvVmZmptzc3NSoUSN16dJFo0ePVtOmTUvsf+nSJa1cuVKbNm3S0aNHlZeXpzp16qh169a65557NHDgQHl42P7xfOHCBSUkJGjjxo366aefVFhYKH9/f4WGhqpnz54aMWLEDbwz+K3IyEj99NNPxV+bTCbVq1dPTZo00f3336/77rvvus+9ZcsWpaWl6amnnnJEVAB/MJR5AH94Xl5eWrdunaZOnSpPT88S21JSUmS1Wsst1/PmzdO8efPk7++v/v37q1mzZioqKtLRo0f18ccfa9myZdq1a5d8fX0lSceOHdOkSZP0448/qmvXrpo0aZL8/f119uxZ7dixQ9OmTdPRo0f1/PPPl5s3NzdXw4cP14kTJ9SvXz8NGzZMZrNZJ06c0Ndff634+HjKvBPcfPPNevbZZyVJRUVFOnXqlJKTk/Xss88qMzNT48ePv67zbtmyRcnJyZR5ANeFMg/gD69Pnz5at26dtmzZonvvvbfEtqSkJN1111368ssvSx23Zs0azZ07V507d9b8+fNVq1atEtufe+45zZs3r/jr/Px8Pfroozp58qTmzp2rvn37lth/0qRJSk1N1f79+23mXbVqlX788Ue98MILGjduXKntmZmZFb5mZ8jNzS3+pcVIrFarLl68KB8fH5v71apVS4MGDSoxNmrUKHXv3l1JSUnXXeYB4EawZh7AH16rVq3UokULJSUllRhPTU3VkSNHNGzYsFLHWCwWxcXFqWbNmoqLiytV5CXJ29tbU6ZMKS64q1ev1g8//KCHHnqoVJG/Jjw8XA8++KDNvD/++KMkqUuXLmVuDwgIKDV27NgxTZs2TXfddZfatGmjbt266fHHH9eBAwdK7LdlyxaNHj1abdu2Vbt27TR69Ght2bKl1PkiIyM1duxYHTx4UA8//LA6dOiggQMHlsj43HPPqVu3bmrTpo0iIyP1+uuv6+LFizZf22/P/+233yo6Olrt2rVTp06dFBsbq7Nnz5ba32KxaOHChbrvvvsUFhamjh076rHHHtPBgwdL7Ldz587i7/WyZct07733KiwsTO+++65duX6rTp068vT0lNlsLjGempqqqVOnql+/foqIiCh+Lzdv3lxiv7Fjxyo5OVmS1KJFi+J/fv1nMTMzU6+88op69eqlNm3aqEuXLnrooYe0bdu2UnlOnTqlZ599VrfffrsiIiL08MMP64cffriu1wbAGLgyDwCShg0bptdee02nTp1S/fr1JV298l6vXj3dfffdpfb/+uuvlZmZqUGDBqlu3bp2zbFx40ZJV6/m3oigoCBJV/+vwZQpUypcX79//36NHz9eV65c0fDhw9W8eXPl5ORo165d2rt3r9q0aSNJWrZsmaZPn67bbrtNTzzxhCQpOTlZTz75pKZPn14qd0ZGhsaNG6eoqCj17du3uKgfOHBA48aNU+3atTVq1CjVr19fhw4dUkJCgvbu3auEhIRS5bcsv/zyi8aPH6++ffuqX79+OnjwoBITE3XgwAGtWbNGNWrUkCQVFBTo4Ycf1t69ezVo0CA9+OCDys3N1apVq3T//ffr/fffV1hYWIlzL126VNnZ2RoxYoQCAgJ08803V5insLBQWVlZkq4us8nMzFR8fLzy8vI0evToEvtu3rxZ33//vaKiotSwYUNlZ2crOTlZMTExmj17tgYMGCBJeuyxx1RUVKSvvvpKM2fOLD6+ffv2kqSTJ0/q/vvv19mzZzVo0CC1adNGly5d0r59+7R9+3bdeeedxcdcvHhRY8aMUUREhCZPnqyTJ08qPj5eTzzxhNatWyd3d/cKXyMAA7ICwB/Ul19+aQ0JCbG+/fbb1qysLGvr1q2t//rXv6xWq9V66dIla4cOHayvvfaa1Wq1Wtu2bWsdM2ZM8bHx8fHWkJAQ67vvvmv3fJ06dbK2b9/+hnNnZ2dbe/ToYQ0JCbF26dLF+tRTT1kXLVpk3b17t7WwsLDEvkVFRdb77rvP2qZNG2taWlqpc13bPzs729q2bVtr7969rRcuXCjefuHCBWuvXr2sbdu2tebk5BSP9+zZ0xoSEmJdtWpVqXMOGDDA2q9fvxLnsVqt1k2bNllDQkKsiYmJFb7Ga+dfsmRJifElS5ZYQ0JCrIsWLSo19tlnn5XY98KFC9YePXqU+L5d+57ffvvt1jNnzlSY47d5fvtPWFiYdcWKFaX2z8vLKzV28eJFa9++fa333HNPifHY2FhrSEhImfM+8sgjZb42q9Va4ns9ZswYa0hIiHXx4sUl9nnrrbfKPR7A7wPLbABAkr+/vyIjI4uXPGzatEkXLlwoc4mNdHV9uKRKrRHPzc2tcF22PerUqaOkpCRNnDhRtWrV0saNG/WPf/xDDz74oHr37q0vvviieN+0tDQdOXJEQ4cOVWhoaKlzubld/Wtg27ZtunjxosaOHVviNfn6+mrs2LG6ePGitm/fXuJYPz8/DR06tMTY4cOHdfjwYfXv318Wi0VZWVnF/3To0EE1a9Ysc3lIWXx9ffXAAw+UGHvggQfk6+tbYrnKRx99pNtuu02tW7cuMZ/FYlHXrl21Z88e5efnlzjPoEGDVK9ePbtyXNOwYUMtWbJES5Ys0bvvvqvXXntNERER+stf/qLExMQS+9asWbP43y9duqRz587p0qVLuuOOO5Senl7858eW7Oxsff755+revbu6d+9eavu1792vv772dKZr7rjjDklXl1kB+H1imQ0A/J9hw4Zp0qRJ+uqrr5SYmKjw8HA1a9aszH2vFd68vDy7z+/r61up/W2pW7eupkyZoilTpujcuXP65ptv9PHHH+ujjz5STEyMUlJSFBwcXLy+vlWrVjbPd/LkSUlS8+bNS227NnbixIkS440bNy61dCM9PV2SNHfuXM2dO7fMuc6cOVPxC/y/8//26UKenp5q3LhxiSzp6enKz88v9x4CSTp37pwaNGhQ/PWtt95qV4Zfq1mzprp27VpibMCAARoyZIheeeUVRUZGyt/fX9LVR5rGxcVp69atZa7xP3/+fIW/CB4/flxWq7XC7901gYGB8vLyKjHm5+cn6eovBgB+nyjzAPB/unXrpvr162v+/PnauXOn/vKXv5S777WC+9sbLG1p3ry5du/erRMnTqhx48Y3GreYv7+/evbsqZ49e6pBgwZauHCh1q9fX7zu3VmurVkvy4QJE8q8mixJtWvXdmgOq9WqkJAQTZs2rdx9fntfg63sleHh4aE77rhD8fHxSk1NVY8ePWS1WjVhwgSlp6crOjpabdq0Ua1ateTu7q7ExEStW7dORUVFDpn/12ytibdarQ6fD0D1QJkHgP/j7u6uwYMHa9GiRfL29lb//v3L3bd9+/YKCAjQli1bdO7cueIrsrb07dtXu3fv1urVq4ufV+5oERERkq4+1USSmjRpIunqchtbrv1yceTIkVJXuI8ePVpiH1uCg4MlXV3y8dur2JV14sQJWSyWElfnLRaLTpw4odtuu63EnOfOndMdd9xRaulJVbhy5Yqk//1fmsOHD+vQoUN68skn9ac//anEvqtXry51vMlkKvO8QUFBMplMFX7vAPyxsWYeAH5l9OjRiomJ0V//+lebyyA8PT31zDPPKC8vT5MnTy5zDfTly5f1xhtvFG8bMWKEmjRponfffbfMxz1KV58Es2zZMpsZ9+7dq/Pnz5e57dp5ry0PCg0NVfPmzZWYmKgjR46U2v/aFds777xTNWvW1Pvvv1/iteTm5ur9999XzZo1Szw5pTytWrVSSEiIVqxYUWpZjnS1+Nq75CM3N1cffPBBibEPPvhAubm56t27d/HY4MGDlZmZqSVLlpR5HnuX9VyPy5cv6/PPP5f0v6VM136h+O3V8O+++67Uoyml/62v/+374ufnp7vuukufffZZqfsVyjo/gD8mrswDwK/ccsstdn8S5/Dhw/XLL79o3rx56tu3b4lPgE1PT9eGDRuUlZWlSZMmSbq6tGPRokWaNGmSnnzySXXr1k1du3aVn5+fsrKytHPnTn3xxRd65JFHbM67du1aJSUlqUePHgoPD5efn5+ys7P16aefaufOnWrWrFnxjbsmk0mvvvqqxo8frxEjRhQ/mvL8+fPavXu3unfvrrFjx6p27dqaMmWKpk+frpEjR2rIkCGSrj6a8tixY5o+fXqZz9L/LZPJpJkzZ2rcuHEaOHCghg0bpmbNmik/P1/Hjh3T5s2b9eyzz5a6cbYsQUFBmj9/vo4cOaLWrVvr22+/VWJiom677TaNHTu2eL/o6Ght375dM2fO1Jdffqk77rhDvr6+ysjI0JdffilPT08lJCRUOF9FLly4oJSUFElXi/Tp06e1du1anThxQiNHjixeh9+0aVM1b95cb7/9tvLz89WkSRP98MMPWrlypUJCQvTtt9+WOG9ERITef/99/fWvf1WPHj1kNpsVHh6uxo0b66WXXtLBgwc1ceJEDR48WK1bt9bly5e1b98+NWzYUM8999wNvy4AxkaZB4AbEBMTox49euj999/Xli1btHz5crm5uSkoKEj33nuv7r///hJX+IODg/Xhhx9q5cqV2rhxoxYuXKiLFy+qTp06atOmjV577bXiZ5CXZ/To0apVq5Z27typJUuWKDs7W2azWcHBwYqJidFDDz1U4mkq4eHhWrNmjRYsWKCPP/5YK1askJ+fn8LDw4ufZy5JDz74oAIDA/XOO+9o/vz5kq5e2Z8/f36JK+EVadmypZKTk7Vo0SJ98sknWrFihXx8fNSwYUMNGTLE5o2qv3bzzTcrLi5Or7/+utavXy+z2awBAwYoNja2xOszm81atGiRPvjgA6WkpBTfeBsYGKiwsLDiX0xu1C+//KLnn3+++OsaNWqoadOm+vOf/1ziOfPu7u5atGiRXn/9dSUnJ+vSpUtq3ry5Xn/9dR06dKhUme/fv7/S0tK0fv16bdiwQUVFRZoxY4YaN26sxo0bKzExUfPnz9dnn32mlJQU1a5dW6GhoTf8eQUAfh9MVv4/HQCgmomMjFTDhg0dckUdAH7PWDMPAAAAGBRlHgAAADAoyjwAAABgUKyZBwAAAAyKK/MAAACAQVHmAQAAAIPiOfM36Ny5PBUVsVIJAAAAjufmZpK/v0+52ynzN6ioyEqZBwAAgEuwzAYAAAAwKMo8AAAAYFCUeQAAAMCgKPMAAACAQVHmAQAAAIOizAMAAAAGRZkHAAAADIoyDwAAABgUZR4AAAAwKMo8AAAAYFCUeQAAAMCgKPMAAACAQXm4OgAAAH8UtfxqyNvsmr968wuu6EL2JZfMDcB5KPMAAFQRb7OHhiT+xyVzJw/rqQsumRmAM7HMBgAAADAoyjwAAABgUJR5AAAAwKAo8wAAAIBBUeYBAAAAg6LMAwAAAAZFmQcAAAAMijIPAAAAGBRlHgAAADAoyjwAAABgUB6uDgAAAGBLHT8feZpdd/3RUlCknOw8l80P2EKZBwAA1Zqn2U2Lk067bP5JQwNdNjdQEZbZAAAAAAZFmQcAAAAMijIPAAAAGBRlHgAAADAoyjwAAABgUJR5AAAAwKAo8wAAAIBBUeYBAAAAg6LMAwAAAAZFmQcAAAAMysPVAQAAxlLLz1veZrNL5s4vKNCF7HyXzA0A1RFlHgBQKd5ms/onvuOSudcNe1gXRJkHgGsMWeYtFovefPNNpaSk6Pz58woNDdXkyZPVpUuXCo/dvn27/vWvf+m7775TUVGRbrvtNo0bN0733ntvFSQHADhTLb8a8ja77q+2/IIrupB9yWXzA/jjMWSZnzp1qjZt2qTo6GgFBwcrOTlZEydOVEJCgtq1a1fucf/5z3/0+OOPq127dnrqqackSevXr9fkyZOVl5enESNGVNVLAAA4gbfZQwPWJLps/rXDh+mCy2YH8EdkuDKfmpqq9evXa9q0aRo/frwkafDgwerfv79mz56tZcuWlXvssmXLFBAQoKVLl8rT01OSNHLkSPXq1UspKSmUeQAAABiK4Z5ms2HDBpnN5hLF28vLS8OHD9eePXt0+vTpco/Nzc1VnTp1iou8JHl6eqpOnTry8vJyam4AAADA0QxX5tPS0tSkSRP5+PiUGA8PD5fValVaWlq5x3bq1ElHjhxRXFycjh8/ruPHjysuLk4//vijJkyY4OzoAAAAgEMZbplNZmam6tevX2o8ICBAkmxemX/sscd0/PhxLVy4UP/6178kSTVr1tSCBQt05513OicwAAAA4CSGK/P5+fkyl/F842vLZC5fvlzusZ6enrr11lsVFRWlPn36qLCwUKtWrdIzzzyj9957T+Hh4ZXOU6+eb6WPAQBcv4CAWq6OYFN1zleds1V3vHeorgxX5r29vVVQUFBq/FqJt7X2/W9/+5v279+vNWvWyM3t6gqje+65R/3799err76qFStWVDrP2bO5KiqyVvo4ADAqV5eazMzynxfj6mxS9c5nK1t15ur3TTLuewfjc3Mz2bx4bLg18wEBAWUupcnMzJQkBQYGlnmcxWLRmjVrdPfddxcXeUkym83q3r279u/frytXrjgnNAAAAOAEhivzoaGh+uGHH5SXl1difN++fcXby5Kdna0rV66osLCw1LYrV67oypUrslq5wg4AAADjMFyZj4qKUkFBgVavXl08ZrFYlJSUpPbt2xffHJuRkaH09PTiferVq6fatWtr8+bNJZbp5OXl6T//+Y9CQkLKXIsPAAAAVFeGWzMfERGhqKgozZ49W5mZmQoKClJycrIyMjI0Y8aM4v1iY2O1a9cuHT58WJLk7u6uCRMmKC4uTqNGjdLAgQNVVFSkNWvW6JdfflFsbKyrXhIAAABwXQxX5iVp5syZiouLU0pKinJyctSiRQstXrxYHTp0sHnc448/rkaNGik+Pl7z58+XxWJRixYtNG/ePPXp06eK0gMAAACOYcgy7+XlpdjYWJtX0xMSEsocHzBggAYMGOCsaAAAAECVMdyaeQAAAABXUeYBAAAAg6LMAwAAAAZFmQcAAAAMijIPAAAAGBRlHgAAADAoyjwAAABgUIZ8zjwAY6jjZ5an2dslc1sK8pWTXeCSuQEAqCqUeQBO42n21isr+7lk7v83aqMkyjwA4PeNZTYAAACAQVHmAQAAAIOizAMAAAAGRZkHAAAADIoyDwAAABgUZR4AAAAwKLsfTfnDDz9o165dOnLkiLKysmQymeTv76+QkBDdfvvtatKkiTNzAgAAAPgNm2X+8uXLSkxM1MqVK/Xdd9/JarWWuZ/JZFJISIhGjx6toUOHysvLyylhAQAAAPxPuWX+ww8/VFxcnE6dOqWOHTtq8uTJateunYKCguTn5yer1aqcnBwdO3ZM33zzjT777DNNnz5dixYt0uTJkzVo0KCqfB0AAADAH065Zf4vf/mLRo8erbFjx6phw4Zl7uPt7a369eurU6dOmjRpkn766SctXbpUf/7znynzAAAAgJOVW+a3bNmim266qVIna9iwoV544QVNnDjxhoMBAAAAsK3cp9lUtsj/WkBAwHUfCwAAAMA+PJoSAAAAMCiHlfn//Oc/mjZtmqNOBwAAAKACDivzhw4d0ocffuio0wEAAACogN0fGgUAAIDS/Px8ZDa7ZuVyQUGRsrPzXDI3qgebZT46OtruE2VkZNxwGAAAAKMxm930ybJMl8wd+SAPHfmjs1nmd+3aJQ8PD5nN5gpPdOXKFYeFAgAAAFAxm2W+fv36atmypRYuXFjhiRYsWKC5c+c6LBgAAAAA22wu8GrVqpUOHDhg14lMJpNDAgEAAACwj80y37p1a505c0anTp2q8ES1atVSgwYNHBYMAAAAgG02y/yECRO0detW+fv7V3iiMWPG6JNPPnFYMAAAAAC22VwzX7NmTdWsWbOqsgAAAACoBJ4zDwAAVMuvprzN7i6bP7+gUBeyL7psfsCoKPMAAEDeZneNSvzOZfOvHBaiCy6bHTCu6/q4snPnzqlly5basWOHo/MAAAAAsNN1f/aw1Wp1ZA4AAAAAlXTdZR4AAACAa1HmAQAAAIOy6wbYjIyMEl/n5ORIkrKyskptu+WWWxwUrXwWi0VvvvmmUlJSdP78eYWGhmry5Mnq0qWLXcevXbtWS5cu1dGjR+Xp6amQkBA9//zzCg8Pd3JyAAAAwHHsKvORkZEymUylxqdMmVJqLC0t7cZTVWDq1KnatGmToqOjFRwcrOTkZE2cOFEJCQlq166dzWPnzJmjt99+WwMHDtSoUaN08eJFHTp0SJmZmU7PDQAAADiSXWX+1VdfLVHm8/Ly9Morr2jChAlq1qyZ08KVJTU1VevXr9e0adM0fvx4SdLgwYPVv39/zZ49W8uWLSv32K+//lqLFi3S3Llz1adPnypKDAAAADiHXWV+6NChJb4+d+6cXnnlFXXr1s3upS2OsmHDBpnNZo0YMaJ4zMvLS8OHD9ecOXN0+vRpBQYGlnlsfHy8wsLC1KdPHxUVFenSpUvy8fGpqugAAACAQxnuBti0tDQ1adKkVAkPDw+X1Wq1ucxnx44dCgsL0xtvvKEOHTqoffv2ioyM1EcffeTs2AAAAIDDGe4TYDMzM1W/fv1S4wEBAZKk06dPl3lcTk6OsrOztX79erm7u2vKlCny8/PTsmXL9Nxzz6lGjRosvQEAAIChGK7M5+fny2w2lxr38vKSJF2+fLnM4y5evChJys7O1qpVqxQRESFJ6tOnj/r06aP58+dfV5mvV8+30scAqBoBAbVcHQFOUN2/r9U5X3XOJlXvfGRDdXVdZb5WrVqKj49Xy5YtHZ2nQt7e3iooKCg1fq3EXyv1v3VtvFGjRsVFXpI8PT3Vr18/xcfHKy8vr9Jr6M+ezVVREZ+GC5TF1X/BZGZecOn8v1fV+fvq6mxS9c5XnbNJ5eerztkk1+fjZ93vm5ubyebF4+sq8x4eHurUqdN1h7oRAQEBZS6lufZoyfJufvXz85Onp6duuummUttuuukmWa1W5ebmckMsAAAADMNwN8CGhobqhx9+UF5eXonxffv2FW8vi5ubm1q2bKlTp06V2vbLL7/I3d1dderUcXxgAAAAwEkMV+ajoqJUUFCg1atXF49ZLBYlJSWpffv2xTfHZmRkKD09vdSxP//8s7Zt21Y8lpubq48//ljt2rWTt7d31bwIAAAAwAEMdwNsRESEoqKiNHv2bGVmZiooKEjJycnKyMjQjBkziveLjY3Vrl27dPjw4eKx+++/X6tXr9ZTTz2l8ePHq3bt2kpMTNSFCxf07LPPuuLlAAAAANfNcGVekmbOnKm4uDilpKQoJydHLVq00OLFi9WhQwebx9WoUUPx8fGaOXOm3n//feXn56t169ZasmRJhccCAAAA1Y0hy7yXl5diY2MVGxtb7j4JCQlljgcEBGjWrFnOigYAAAA71a1TU+6e7i6Zu9BSqKyciy6Z25EMWeYBAABgfO6e7vrljW9dMvfNz7Z2ybyOdt03wGZlZSkrK8uRWQAAAABUQqWuzJ86dUpvvPGGtm7dWvxoSF9fX/Xq1UuTJ08ufpIMAAAAAOezu8xnZGRo5MiROnPmjFq2bKlmzZpJktLT0/Xhhx9q27ZtWrVqlRo0aOC0sAAAAAD+x+4y/+abb+r8+fNatGiRevToUWLbp59+qqeeekpvvvmmXnvtNYeHBAAAAFCa3Wvmt23bpgceeKBUkZekHj166P7779fnn3/u0HAAAAAAymd3mc/JyVFwcHC524ODg3X+/HmHhAIAAABQMbvL/M0336xdu3aVu/2rr77SzTff7JBQAAAAACpmd5mPiorShg0b9I9//EMXLlwoHs/NzdUbb7yhjz/+WPfee69TQgIAAAAoze4bYJ944gl99dVXeuutt/Tuu+8qMDBQknT69GkVFhaqffv2evzxx50WFAAAAEBJdpf5GjVqKCEhQUlJSdqyZYtOnjwpSerWrZt69+6tIUOGyMODD5QFAAAAqkql2reHh4dGjhypkSNHOisPAFSJWn6e8jZ7uWz+/ILLupBtcdn8AIDfB7vLfHR0tB5//HF16dKlzO1ffvmlFixYoPj4eIeFAwBn8TZ76Z6U+102/8eDluuCKPMAgBtj9w2wu3bt0pkzZ8rdnpWVpd27dzskFAAAAICK2V3mK3L+/Hl5eno66nQAAAAAKmBzmc2hQ4d06NCh4q+/+uorFRYWltovOztby5cvV9OmTR2fEAAAAECZbJb5LVu2aN68eZIkk8mklStXauXKlWXu6+PjoxdffNHxCQEAAACUyWaZHzJkiDp16iSr1apx48bp0Ucf1Z133lliH5PJpJo1a6pZs2by8nLdkyEAAACAPxqbZb5hw4Zq2LChJGnGjBm6/fbb1ahRoyoJBgAAAMA2ux9NOWTIEGfmAAAAAFBJDnuaDQAAAICqRZkHAAAADIoyDwAAABgUZR4AAAAwKMo8AAAAYFCUeQAAAMCgHFbmU1JSFB0d7ajTAQAAAKiAw8p8RkaGdu/e7ajTAQAAAKgAy2wAAAAAg7L5CbC9evWy+0S5ubk3HAYAAACA/WyW+Z9++kl16tRRYGBghSfKz893WCgAAAAAFbNZ5hs1aqTg4GC98847FZ5owYIFmjt3rsOCAQAAALDN5pr51q1b69tvv7XrRCaTySGBAAAAANjHZplv1aqVspCKkmsAACAASURBVLOzdfLkyQpPdMstt6hjx44OCwYAAADANptl/tFHH9WhQ4fUqFGjCk80aNAgJSQkOCwYAAAAANt4NCUAAABgUNdd5ouKipSRkSGLxeLIPAAAAADsdN1lPisrS7169dKePXscmQcAAACAnW5omY3VanVUjkqxWCyaNWuWunXrpvDwcI0cOVI7duyo9HkmTpyoFi1a6O9//7sTUgIAAADOZcg181OnTtXSpUs1cOBAvfjii3Jzc9PEiRO1d+9eu8/x3//+V1999ZUTUwIAAADOZbgyn5qaqvXr12vKlCl6/vnnNWrUKC1dulQNGjTQ7Nmz7TqHxWLRjBkz9PDDDzs5LQAAAOA8113mvb29NWTIEAUGBjoyT4U2bNggs9msESNGFI95eXlp+PDh2rNnj06fPl3hOeLj45Wfn0+ZBwAAgKFdd5n39fXVjBkz1LRpU0fmqVBaWpqaNGkiHx+fEuPh4eGyWq1KS0uzeXxmZqYWLFigyZMnq0aNGs6MCgAAADiVh6sDVFZmZqbq169fajwgIECSKrwy/8Ybb6hJkyYaNGiQU/Lh+vjX8ZSHp5dL5r5iuaxzOTxiFQAAGE+5Zf6BBx7Q5MmTdfvtt1fqhDt27NA///lPLV++/IbDlSU/P19ms7nUuJfX1SJ4+fLlco9NTU3Vhx9+qISEBJlMJofkqVfP1yHngbR34QCXzNvusbUKCHDNLxJwroCAWq6OYFN1z1ddVff3rTrnq87ZpOqdj2y/T7+H967cMh8YGKixY8eqVatWGjx4sO666y7deuutZe579OhRffrpp0pJSdGRI0d07733OiuvvL29VVBQUGr8Wom/Vup/y2q16u9//7v69u2rjh07OizP2bO5KipyzSM6f09c/R9TZuYFl87/e1Wdv6+uziYZ98+dq987I39fXZ2vOmeTys9XnbNJrs9n1J8lEu+dPdzcTDYvHpdb5uPi4rRnzx4tWLBAM2bM0IwZM1S7dm01bNhQfn5+slqtysnJ0fHjx5WXlyeTyaRu3bpp+vTpatu2rVNejHR1OU1ZS2kyMzMlqdwbcjdv3qzU1FRNnjxZJ0+eLLEtNzdXJ0+e1E033SRvb2/HhwYAAACcwOaa+Q4dOuidd97R8ePHtWHDBu3evVvp6en6/vvvZTKZ5O/vr44dO6pTp07q27evGjVq5PTAoaGhSkhIUF5eXombYPft21e8vSwZGRkqKirSuHHjSm1LSkpSUlKS3nrrLd11113OCQ4AAAA4mF03wAYFBWnSpEmaNGmSs/NUKCoqSu+++65Wr16t8ePHS7r63PikpCS1b9+++ObYjIwMXbp0qfhpO5GRkWX+svHkk0+qZ8+eGj58uFq3bl1lrwMAAAC4UYZ7mk1ERISioqI0e/ZsZWZmKigoSMnJycrIyNCMGTOK94uNjdWuXbt0+PBhSVd/IQkKCirznI0bN1bv3r2rJD8AAADgKIYr85I0c+ZMxcXFKSUlRTk5OWrRooUWL16sDh06uDoaAAAAUGUMWea9vLwUGxur2NjYcvdJSEiw61zXrtwDAAAARnPdnwALAAAAwLUo8wAAAIBBUeYBAAAAg6LMAwAAAAZVqTJfWFioDz/8UFOmTNFDDz2kgwcPSpJycnL04Ycf6tSpU04JCQAAAKA0u59mc+nSJU2YMEF79+5VjRo1lJ+fr5ycHEmSr6+vZs+erWHDhmny5MlOCwsAAADgf+y+Mj937lwdOHBA8+bN09atW2W1Wou3ubu7q2/fvvriiy+cEhIAAABAaXaX+Q0bNmjUqFHq3bu3TCZTqe1BQUH66aefHBoOAAAAQPnsLvOnT59WixYtyt1eo0YN5eXlOSQUAAAAgIrZXeb9/Pxs3uB65MgRBQYGOiQUAAAAgIrZXea7dOmipKQkXbp0qdS2EydOKDExUd27d3doOAAAAADls/tpNjExMRo2bJiGDx+u++67TyaTSZ9//rm2b9+uFStWyNPTU48++qgzswL4jTp+ZnmavV02v6UgXznZBS6bHwCAPzq7y3xwcLDee+89vfDCC/rnP/8pSXr33XclSc2bN9esWbPUoEED56QEUCZPs7feXdrXZfNPGLdJEmUeAABXsbvMS1KbNm300Ucf6bvvvlN6erqsVqtuvfVWtWrVyln5AAAAAJTDrjKfl5enQYMGacyYMRo/frxCQkIUEhLi7GwAAAAAbLDrBlgfHx9lZ2fLx8fH2XkAAAAA2Mnup9lERERo//79zswCAAAAoBLsXjM/ZcoUjRs3ThERERo6dGiZnwILAACA6sO/jo88PO2+dutwVyxFOpfDh4o6k91lfsaMGapdu7b+3//7f5o1a5aCgoLk7V3ykXgmk0lLly51eEgAAABUnoenm47MK/9DP52teUx9l839R2F3mT958qQkFT9+8syZM85JBAAAAMAudpf5Tz75xJk5AAAAAFSS6xZRAQAAALghlfrQKEnKzc3V9u3bdeLECUlS48aN1bVrV/n6+jo8HAAAAIDyVarMr169Wq+99pouXrwoq9Uq6epNrzVr1tTUqVM1YsQIp4QEAAAAUJrdZX7r1q166aWX1LhxYz399NNq3ry5JOnIkSN6//339fLLL6tevXqKjIx0WlgAAAAA/2N3mX/77bfVtGlTrVq1qsQnwXbp0kVDhw7VqFGj9NZbb1HmAQAAgCpi9w2whw4d0pAhQ0oU+Wt8fX01ePBgHTp0yKHhAAAAAJTPYU+z4RNhAQAAgKpld5lv0aKFkpOTdfHixVLb8vLylJycrNDQUIeGAwAAAFA+u9fMP/LII4qJidGQIUMUHR2tpk2bSpKOHj2qhIQEHT9+XHPnznVaUAAAAAAl2V3me/furZdeekmzZ8/W3/72t+JlNVarVTVq1NBLL72k3r17Oy0oAAAAgJIq9Zz5Bx98UAMGDNC2bdt08uRJSVc/NOrOO+9UrVq1nBIQAAAAQNkq/QmwtWvX1j333OOMLAAAAAAqwe4bYA8ePKhly5aVu33ZsmVKS0tzSCgAAAAAFbO7zM+bN0///e9/y93+2Wefaf78+Y7IBAAAAMAOdi+z2b9/v8aOHVvu9ttvv13x8fEOCQVUJ351PGX29HLJ3AWWy8rOsbhkbgAAUP3ZXebPnTsnPz+/crfXrl1b586dc0gooDoxe3rp3+/c65K5733435Io8wAAoGx2L7OpV6+ejhw5Uu727777TnXq1HFIKAAAAAAVs7vMd+3aVWvWrCmz0B89elSJiYnq2rWrQ8OVx2KxaNasWerWrZvCw8M1cuRI7dixo8LjNm3apGeeeUaRkZGKiIhQVFSUXn/9dV24cKEKUgMAAACOZfcym8cff1ybNm3S8OHDNWzYMLVs2VKSlJaWpsTERJnNZj3xxBNOC/prU6dO1aZNmxQdHa3g4GAlJydr4sSJSkhIULt27co97qWXXlJgYKAGDRqkW265RYcPH1ZCQoI+//xzJSYmysvLNeuiAQAAgOthd5kPCgrSe++9p2nTpumDDz4osa158+Z69dVXdeuttzo6Xympqalav369pk2bpvHjx0uSBg8erP79+2v27Nk2H5/5z3/+U507dy4x1qZNG8XGxmr9+vUaOnSoM6MDAAAADlWpD40KCwvTunXrlJaWph9//FGS1KRJE4WGhjojW5k2bNggs9msESNGFI95eXlp+PDhmjNnjk6fPq3AwMAyj/1tkZek3r17S5LS09OdExgAAABwkkp/AqwktWzZsniZTVVLS0tTkyZN5OPjU2I8PDxcVqtVaWlp5Zb5spw5c0aS5O/v79CcAAAAgLNdV5mXpBMnTmj9+vU6deqUmjVrpmHDhsnb29uR2cqUmZmp+vXrlxoPCAiQJJ0+fbpS53vrrbfk7u6uvn37OiQfAAAAUFVslvnVq1crISFBS5YsUb169YrHt23bppiYGOXn58tqtcpkMmnFihVasWJFqSvmjpafny+z2Vxq/NrNq5cvX7b7XGvXrtWaNWv06KOPKigo6Lry1Kvne13HoXoJCKjl6gjlqs7ZpOqdrzpnk6p/vuqqur9v1Tlfdc4mVe98ZLt+1Tlfdc5mL5tl/r///a98fHxKFHmr1aqXX35Z+fn5mjRpktq2bavNmzcrKSlJ7733np588kmnBvb29lZBQUGp8Wsl3t4n0nz11Vd68cUXdffdd+vpp5++7jxnz+aqqMh63cfjKlf/x5SZWf7jSclmW3XOV52zSbbzVWeufu+M/H11db7qnE0qP191zia5Pl91ziZV73xG+Dns5mayefHYZpk/dOiQ7rnnnhJjX3/9tX766ScNHjxYkydPliT17NlTP/30k7Zu3er0Mh8QEFDmUprMzExJsmu9/KFDh/T444+rRYsWmjNnjtzd3R2eEwAAAHA2mx8alZWVpcaNG5cY+/rrr2UymUqV/B49eujYsWOOT/gboaGh+uGHH5SXl1difN++fcXbbTl+/LgeeeQR1a1bV4sWLVLNmjWdlhUAAABwJptl3sPDo9SSlv3790uS2rZtW2Lcz89PFovFwfFKi4qKUkFBgVavXl08ZrFYlJSUpPbt2xffHJuRkVHqcZOZmZmaMGGCTCaT3nnnHdWtW9fpeQEAAABnsbnMpmHDhtq7d6/GjBkjSSosLNSePXsUHBysOnXqlNg3Ozu7Sh7vGBERoaioKM2ePVuZmZkKCgpScnKyMjIyNGPGjOL9YmNjtWvXLh0+fLh47JFHHtGJEyf0yCOPaM+ePdqzZ0/xtqCgIJufHgsAAABUNzbLfN++fbVgwQK1a9dOd9xxhxITE5WVlaVhw4aV2jc1NVWNGjVyWtBfmzlzpuLi4pSSkqKcnBy1aNFCixcvVocOHWwed+jQIUnS22+/XWrbkCFDKPMAAAAwFJtlPjo6WikpKfr73/8u6eqTbBo0aKCHHnqoxH4XLlzQp59+qvHjxzst6K95eXkpNjZWsbGx5e6TkJBQauzXV+kBAAAAo7NZ5n19fZWYmKhVq1bp2LFjCgoK0ogRI1S7du0S+6Wnp2vo0KG67777nBoWAAAAwP9U+Amwvr6+mjBhgs192rZtW+qGWAAAAADOZfNpNgAAAACqL8o8AAAAYFCUeQAAAMCgKPMAAACAQVHmAQAAAIOizAMAAAAGZbPMFxYWavbs2Vq+fLnNk3zwwQd64403ZLVaHRoOAAAAQPlslvmPPvpI77zzjsLCwmyeJDw8XG+99ZbWrVvn0HAAAAAAymezzH/88cfq2rWr2rRpY/Mkbdq0Ubdu3bR+/XqHhgMAAABQPptl/ttvv1WXLl3sOlHnzp114MABh4QCAAAAUDGbZT4nJ0f16tWz60R169ZVdna2Q0IBAAAAqJjNMu/j46Nz587ZdaLs7Gz5+Pg4JBQAAACAitks882aNdO2bdvsOtG2bdvUrFkzh4QCAAAAUDGbZb5Pnz7avn27tmzZYvMkW7du1fbt29W3b1+HhgMAAABQPptlfvTo0QoKCtIzzzyjOXPm6OTJkyW2nzx5UnPmzNEzzzyjW2+9VaNHj3ZqWAAAAAD/42Fro7e3txYvXqxHH31UixYt0uLFi+Xr6ysfHx/l5eUpNzdXVqtVTZo00aJFi+Tl5VVVuQEAAIA/PJtlXpKCg4OVkpKiVatWaePGjTpy5IjOnDkjHx8fdezYUX379tWIESPk7e1dFXkBAAAA/J8Ky7wkeXl5aezYsRo7dqyz8wAAAACwk80185J08eJF5eXl2dwnLy9PFy9edFgoAAAAABWzWea///57derUSYsWLbJ5ksWLF6tTp046fvy4Q8MBAAAAKJ/NMr9ixQr5+/srJibG5kmeeOIJ1a1bV8uXL3doOAAAAADls1nmd+zYoX79+snT09PmSby8vBQVFWX3B0wBAAAAuHE2y/zJkyfVvHlzu07UtGlTnThxwiGhAAAAAFTMZpkvKiqSm1uF98hePZGbm4qKihwSCgAAAEDFbDb1gIAAHT161K4THT16VAEBAQ4JBQAAAKBiNst8x44dtW7dOrseTblu3TrdfvvtDg0HAAAAoHw2y/yDDz6orKwsxcTEKDs7u8x9cnJyFBMTo3PnzmnMmDFOCQkAAACgNJufABsWFqYnn3xS8+bNU69evdS3b1+1aNFCvr6+ysvLU1pamrZs2aLc3Fw99dRTat26dVXlBgAAAP7wbJZ5SYqJidHNN9+suLg4JScnS5JMJpOsVqsk6aabbtK0adM0bNgw5yYFAAAAUEKFZV6Shg8frkGDBunrr7/WkSNHlJubK19fXzVv3lzt27eX2Wx2dk5DqFvHW+6ernkvCi0FysrJd8ncAAAAcA27yrwkmc1mde7cWZ07d3ZmHkNz9zQr81/vu2TugMfHSKLMAwAA/JHY9xB5AAAAANWOzSvz0dHRlTqZyWTS0qVLbygQAAAAAPvYLPO7du2Sh4eH3WviTSaTQ0IBAAAAqJjNMu/hcXVz165dNXToUPXs2VNubqzMAQAAAKoDm838s88+07PPPqvjx48rJiZGd911l2bNmqXvv/++qvIBAAAAKIfNMl+3bl1NmDBBa9eu1cqVKxUZGalVq1bpvvvu06hRo7R69Wrl5eVVVdZiFotFs2bNUrdu3RQeHq6RI0dqx44ddh176tQpPf300+rYsaPat2+vJ554QidOnHByYgAAAMDx7F4zEx4erunTp+uLL77Q66+/rho1aujll19Wt27dlJKS4syMpUydOlVLly7VwIED9eKLL8rNzU0TJ07U3r17bR6Xl5en6Oho7dmzR4899pj+9Kc/6eDBg4qOjlZOTk4VpQcAAAAcw+7nzF/j5eWlgQMHqmHDhnJzc9P27dur9Mp2amqq1q9fr2nTpmn8+PGSpMGDB6t///6aPXu2li1bVu6xH3zwgY4dO6akpCS1atVKktS9e3cNGDBA7733np5++umqeAkAAACAQ1TqbtbTp09r8eLFioqK0pgxY5Senq5HH31Uw4YNc1a+UjZs2CCz2awRI0YUj3l5eWn48OHas2ePTp8+Xe6xGzduVNu2bYuLvCQ1bdpUXbp00ccff+zU3AAAAICjVXhlvqCgQFu3blVSUpK2bdsmNzc3RUZGatq0aerevXuVP90mLS1NTZo0kY+PT4nx8PBwWa1WpaWlKTAwsNRxRUVFOnz4sEaNGlVqW1hYmLZt26ZLly6pRo0aTssOAAAAOJLNMv/KK69o7dq1On/+vEJCQhQbG6uBAwfKz8+vqvKVkpmZqfr165caDwgIkKRyr8xnZ2fLYrEU7/fbY61WqzIzMxUUFOTYwAAAAICTmKxWq7W8jaGhofL29lbv3r3VunXrik9mMhWvY3eW3r17q1mzZlq4cGGJ8RMnTqh379566aWXNGbMmFLH/fzzz7r77rs1depUPfTQQyW2rVmzRi+++KLWrl2rkJCQ685mvVIok4f7dR9/Iyqa23qlQCYP+z78yxkqmr/oikVuHp5VmMj+uQuvWOTuomwVzX2l0CIPd9dks2d+V+araG5LoUWeLnzvXD3/jbAUXpGne6VvuaqSuS2FhfJ0d83PYXvmd2W+irMVydPddZ8lY2v+K4VWebi77oMpK5q/sNAqdxflq2juoitWuXm47r2raH7rlSKZPFzz586VcztShT+N8/PztW7dOq1bt67Ck1VFmff29lZBQUGp8cuXL0u6un6+LNfGLRZLucd6e3tXOs/Zs7kqKir396FqIyCgln5e8KLL5m/wxN+VmXmhgr0uV0mW65ubbNc/P+9d9Z0fAFDdubmZVK+eb7nbbZb5+Ph4hwe6UQEBAWUupcnMzJSkMtfLS5Kfn588PT2L9/vtsSaTqcwlOAAAAEB1ZbPMd+rUqapy2C00NFQJCQnKy8srcRPsvn37ireXxc3NTSEhITpw4ECpbampqQoODubmVwAAABiK4RYKRUVFqaCgQKtXry4es1gsSkpKUvv27Ytvjs3IyFB6enqJY/v166dvvvlGBw8eLB77/vvv9eWXXyoqKqpqXgAAAADgIK65g+kGREREKCoqSrNnzy5++kxycrIyMjI0Y8aM4v1iY2O1a9cuHT58uHjsgQce0OrVqzVp0iQ99NBDcnd313vvvaeAgACnr/UHAAAAHM1wZV6SZs6cqbi4OKWkpCgnJ0ctWrTQ4sWL1aFDB5vH+fr6KiEhQa+++qoWLFigoqIide7cWS+++KL8/f2rKD0AAADgGDYfTYmK8TQb+9j3NBsAAAD8WkVPszHcmnkAAAAAV1HmAQAAAIOizAMAAAAGRZkHAAAADIoyDwAAABgUZR4AAAAwKMo8AAAAYFCUeQAAAMCgKPMAAACAQVHmAQAAAIOizAMAAAAGRZkHAAAADIoyDwAAABgUZR4AAAAwKMo8AAAAYFCUeQAAAMCgKPMAAACAQVHmAQAAAIOizAMAAAAGRZkHAAAADIoyDwAAABgUZR4AAAAwKMo8AAAAYFCUeQAAAMCgKPMAAACAQVHmAQAAAIOizAMAAAAGRZkHAAAADIoyDwAAABgUZR4AAAAwKMo8AAAAYFCUeQAAAMCgKPMAAACAQVHmAQAAAIOizAMAAAAGRZkHAAAADIoyDwAAABgUZR4AAAAwKA9XB7ge58+f16xZs7R582bl5+crPDxc06ZNU8uWLW0eV1RUpOTkZG3evFlpaWnKyclRo0aN1L9/f02YMEGenp5V9AoAAACAG2e4K/NFRUWaNGmS1q9frzFjxui5557T2bNnNXbsWB0/ftzmsZcuXdILL7ygc+fOafTo0XrhhRcUFhamN998U5MmTaqiVwAAAAA4huGuzG/YsEF79+7V/Pnz1bt3b0nSPffco379+mnevHmaOXNmuceazWYtX75c7du3Lx4bOXKkGjZsqLlz52rnzp3q3Lmz018DAAAA4AiGuzK/ceNGBQYGqlevXsVjdevW1T333KMtW7aooKCg3GM9PT1LFPlr+vTpI0lKT093fGAAAADASQxX5tPS0tS6dWuZTKYS42FhYcrLy6twqU1Zzpw5I0ny9/d3SEYAAACgKhiuzGdmZiowMLDU+LWx06dPV/qcb7/9tmrVqqVu3brdcD4AAACgqrh0zXxRUZHNZTG/5uXlJUnKz88v86kz18by8/MrlWHhwoXavn27pk+frlq1alXqWEmqV8+30sf8UQUEVP79BQAAQPlcWuZ3796t6Ohou/bdsWOH6tatK29vb1ksllLbr415e3vbPf+///1vxcXFadSoURo1apTdx/3a2bO5KiqyXtexVak6FOnMzAuujgAAAGAobm4mmxePXVrmb7vtNs2YMcOufX19r76IgICAMpfSXBsrawlOWbZt26bnn39ePXv21J///Gc7EwMAAADVh0vLfEBAgIYOHVqpY0JDQ7V3715ZrdYSN8GmpqaqZs2aCgoKqvAc+/btU0xMjMLCwjRnzhy5u7tXOjsAAADgaoZ7znxUVJQ2btyorVu3Fj9nPisrSxs2bFCvXr1kNpuL9732ZJtfF/z09HRNmjRJDRs21MKFCyu1LMfICi0WNXji7y6dHwAAAI5lslqt1X/B968UFhbqgQce0JEjRzRhwgT5+/tr+fLl+vnnn5WUlKTg4ODifSMjIyVJn3zyiSQpNzdX/fv316lTpzR58mTVr1+/xLlbtGih0NDQSuUxypp5AAAAGE+1XjN/Pdzd3bV48WLNnDlTCQkJunz5ssLCwvT666+XKPJlyc7O1s8//yxJ+sc//lFqe0xMTKXLPAAAAOAqhrsyX91wZR4AAADOUtGVecN9aBQAAACAqyjzAAAAgEFR5gEAAACDoswDAAAABkWZBwAAAAyKMg8AAAAYFGUeAAAAMCjKPAAAAGBQlHkAAADAoCjzAAAAgEF5uDqA0bm5mVwdAQAAAL9TFXVNk9VqtVZRFgAAAAAOxDIbAAAAwKAo8wAAAIBBUeYBAAAAg6LMAwAAAAZFmQcAAAAMijIPAAAAGBRlHgAAADAoyjwAAABgUJR5AAAAwKAo8wAAAIBBebg6wB+ZxWLRm2++qZSUFJ0/f16hoaGaPHmyunTp4upoOn36tOLj47Vv3z4dOHBAFy9eVHx8vDp37uzqaEpNTVVycrJ27typjIwM+fn5qV27dnrmmWcUHBzs6njav3+/Fi5cqIMHD+rs2bOqVauWQkND9eSTT6p9+/aujlfKW2+9pdmzZys0NFQpKSkuy7Fz505FR0eXue3f//63mjZtWsWJypaamqp58+Zp7969unLliho3bqzx48dr6NChLss0depUJScnl7v9s88+U/369aswUWk//vij4uLi9PXXX+v8+fO65ZZbNHjwYI0fP16enp4uzfbNN99ozpw5Sk1NlZubmzp37qypU6cqKCioSnNU5ufu1q1bNW/ePB09elT16tXT8OHD9dhjj8nDwzl/rdubbfny5fryyy+VmpqqjIwMDRkyRK+99ppTMlUm27lz55SYmPj/27v3sBrz/f/jz9AXkQ4jjHKImRZyiEyIa2ZTQ5tpMA7RhEZbmzFt2Q4Tw+Zy3jO0UU67wTiO0wgZMw4x7BqZIeRYctiEUtJxqZXW/fvDt/WzFJr5VneN9+O6XJf7s9Zqvbqv1n2/132/78/N0aNHuXHjBk+ePKFly5b4+vry5z//WfV8iqIwa9Yszp49y/379yksLKRJkyYMHjyY4cOHY2pqqlq25929e5e+ffuSl5fHnj17aN26dblk+y35evXqxd27d4u9fsyYMUyePFnVbADZ2dmsWLGCgwcPkpqayhtvvIGzszPBwcFlkkWKeRUFBQVx6NAhRo4cSbNmzQgPD2fMmDFs2rSJjh07qprt5s2bhIWF0axZMzQaDWfPnlU1z7O+/vprYmNj8fDwQKPRkJqaypYtWxgwYAC7du1Svei7c+cOhYWFDBkyBBsbG7Kzs4mIiMDHx4ewsDC6d++uar5npaamsmrVKszMzNSOYjBq1CgcHR2NnmEW/wAAFghJREFUxtQuRIscP36c8ePH4+LiwoQJE6hRowa3bt3i/v37quby8vIqdhBAURRmz56Nra2t6usvJSWFIUOGYG5ujo+PDxYWFpw+fZolS5Zw7do1vvrqK9WyxcXF4ePjg62tLQEBAej1erZu3Yq3tzd79uyhfv36FZaltNvdor/Drl27MnPmTBISElixYgWPHj1i5syZqmYLCwsjJyeHdu3akZqaWi5Zfk+2c+fOsXTpUt59913GjRtHjRo1OHjwIIGBgdy4cYPx48ermk+v13Pp0iV69OiBnZ0d1atX59y5cyxYsICLFy/y5Zdfqpbtef/85z+pVq1iGjt+Sz5HR0dGjRplNObg4KB6tqysLD7++GOysrIYMmQIjRo1IjU1lV9//bXswihCFefPn1ccHByU9evXG8by8vIUd3d3xdvbW71g/ys7O1tJT09XFEVRDh8+rDg4OCgxMTEqp3rqzJkzSn5+vtHYzZs3lbZt2yqff/65SqleTqvVKq6uroq/v7/aUYx8/vnnyogRIxQfHx/lww8/VDVLTEyM4uDgoBw+fFjVHC+SlZWldOvWTZk7d67aUUrl119/VRwcHJRVq1apHUVZs2aN4uDgoCQkJBiNBwQEKG3atFF0Op1KyRTFz89PcXFxUTIyMgxjKSkpipOTkzJv3rwKzVLa7W7fvn2VgQMHKk+ePDGMBQcHK61atVJu3ryparakpCRFr9criqIozs7OFbJNLk2227dvK0lJSUZjer1eGTlypNK+fXvl8ePHquZ7kblz5yoajUZ5+PBhpcgWExOjODo6KsHBwYqDg4Ny+fLlcsn1W/P17NlTGTduXLlm+b3ZZs6cqfTq1cvw3PIgPfMq+fHHHzE1NWXIkCGGsZo1azJ48GDOnDnDgwcPVEwHdevWxcrKStUML9KpU6dip+WbN2/O22+/zfXr11VK9XK1a9fG2tqarKwstaMYxMXFsW/fPqZNm6Z2lGJycnJ48uSJ2jGMREREkJWVxYQJE4CnGRVFUTnVi+3fvx8TExM++OADtaOQm5sLwBtvvGE0Xr9+fWrUqEH16tXViAVAbGwsPXr0wMLCwjDWoEEDXFxc+OGHHyo0S2m2u4mJiSQmJuLl5WW03ry9vdHr9Rw6dEi1bAC2traYmJiUS4YXKU22Jk2aYGtrazRmYmKCu7s7eXl5JbZoVGS+F2ncuDGKopCdnV3GqZ76LdkKCwuZP38+Pj4+FdbS+lvXnU6n4/Hjx+WY6P8rTbasrCzCw8Px8/PDysqK/Px8dDpdmWeRYl4lV65cwd7enjp16hiNt2/fHkVRuHLlikrJqiZFUUhLS6tUX0BycnJIT0/nxo0bBAcHk5CQUCmuh4Cn62vu3LkMGDCgXPsdf48pU6bg7OxMhw4dGD16NPHx8WpHAuDkyZO0aNGC48eP89577+Hs7IyLiwuLFy+msLBQ7XhGCgoK+OGHH+jYsSN2dnZqx+Gdd94B4IsvvuDq1avcv3+fffv2GVoLK+qUfUl0Oh01a9YsNl6rVi1SU1NVP7DyvMuXLwPQtm1bo/GGDRvSqFEjw+OidNLS0gAqzb6joKCA9PR07t+/z+HDh1m3bh1NmjSpFJ/jbdu2kZKSwqeffqp2lBJFR0fj5OSEk5MT7u7ubN++Xe1InD59Gp1OR/369fH19aVDhw44OTkxevRobt++XWbvIz3zKklNTS2xj9XGxgag0u1AKrt9+/aRkpLCxIkT1Y5iMH36dA4ePAiAqakpw4YNY+zYsSqnemrPnj0kJiayYsUKtaMYmJqa0qdPH959912srKyIj49n3bp1eHt7s2vXLuzt7VXN99///pfk5GSCgoL4y1/+Qps2bTh27BhhYWHk5+fzxRdfqJrvWVFRUWRkZODp6al2FAB69OjBhAkTWLNmDUePHjWM/+1vfyvXXuXSsLe359y5c+j1esOXCp1OR1xcHPB0W9ygQQM1Ixop6kMv2lc8y8bGRvYdv0FGRgY7d+7ExcUFa2trteMATz+7z+4n2rZty8KFC1U9ewVP19Xy5csJCAigXr16qmYpiYODA507d6Z58+Y8evSIHTt28I9//IPMzEz8/f1Vy1VUsM+cOZO2bdsSHBzMgwcPCA0NZdSoUURERFC3bt3/8/tIMa+SvLy8Eq9OLzpClJ+fX9GRqqzr168zZ84cnJ2d6d+/v9pxDMaPH4+XlxfJycns3bsXnU5HQUGB6jN35OTksGTJEvz9/StVkdKpUyej2X7c3Nzo1asXgwYNIjQ0lCVLlqiYDrRaLZmZmUyaNMmwc+jduzdarZZvv/2WcePGVZqCYP/+/Ziampb7LB2/hZ2dHS4uLrz//vtYWlry008/ERISgrW1NcOHD1ctl7e3N7Nnz2bGjBmMHj0avV7PqlWrDEVzXl6eatlKUpSnpO1IzZo1K6zFoKrT6/VMnjyZ7OxsZsyYoXYcgw4dOrB+/Xqys7OJiYnhypUraLVatWOxfPlyrK2tGTZsmNpRSrR69Wqj5Y8++ghvb29WrlzJ8OHDMTc3VyVXUYuhjY0NYWFhhgMG9vb2+Pv789133xW7aPf3kDYbldSqVYuCgoJi40VFfEmnfUVxqamp/PWvf8XCwoJly5aperr+eRqNhu7duzNo0CDWrl3LpUuXKkV/+qpVqzA1NeWTTz5RO8ortWrVim7duhETE6N2FGrVqgVQrAfd09OTgoICLly4oEasYnJzc4mMjKRHjx6VpnXg+++/Z9asWcybN4+hQ4fSu3dvFixYwMCBA/nyyy/JzMxULdvw4cMZO3Ys+/bto1+/fnh6enL79m38/PwAirVCqq3o77Ckvtv8/HzD4+Ll5s6dS1RUFAsXLkSj0agdx8Da2hpXV1f69OnDrFmzcHNz45NPPqmwmYFKkpCQwLZt2wgKCiq3qU/LWvXq1Rk1ahSPHz9WdTa+os+jh4eHUX3y3nvvYWFhQWxsbJm8T+WpfF4zLzodWvSBrUxHTCur7OxsxowZQ3Z2Nl9//XWJp50rC1NTU9zc3Dh06JCqR/oePHjAhg0b8Pb2Ji0tjaSkJJKSksjPz6egoICkpCRVC6uSvPnmm5UiU9Hf1/NTFRYtV4aMAEeOHOHx48eVpsUGYOvWrTg6OhZrLezVqxdarZarV6+qlOypiRMnEh0dzZYtW9i3bx/fffcdiqJgYmJCkyZNVM32vKK/w5KKu9TUVNl3lEJoaChbt25lypQpleIC8Zfx8PBAq9USGRmpWobg4GDatGlDy5YtDfuMR48eAU/3KWpPzfsijRo1AtTdNr9ovwGU6aQYVeMr1h9Qq1at2LRpE7m5uUZHfs6fP294XLxYfn4+Y8eO5datW3zzzTe0aNFC7UivlJeXh6Io5Obmqnb07OHDhxQUFLB48WIWL15c7HE3N7dyvcnG73Hnzp1KcYTZ0dGRn3/+mZSUFKMCLzk5GaDStNhERERgZmZGr1691I5ikJaWVuL6KTo7WRkuILawsKBz586G5Z9//pn27duXST9rWSq6YP3ixYtG92NISUkhOTm50l3QXtls2bKFkJAQfH19DWdfKrOigz/lNZtNady/f5+rV6/i5uZW7DF/f3/q169PdHS0Csle7s6dO4C62+aiz2hKSorRuF6vJzU1tdg9VX4vKeZV4uHhwbp169i5cye+vr7A09Omu3fvplOnTqrf5KUyKywsJDAwkHPnzrFy5UqcnJzUjmQkPT292MYjJyeHgwcP8uabbxabnq8i2dnZlXjR69KlS9FqtUyfPp3mzZtXfDBKXm+nT5/m1KlTDBgwQJVMz/Lw8CAsLIxdu3YZLrRWFIWdO3diZmZWKf4O09PTOXnyJP369aN27dpqxzGwt7cnOjqa27dvG91V9fvvv6d69eqVqs0Bnt5x+MKFC2V2d8ay9Pbbb9OiRQu2b9/O4MGDDRdGfvvtt1SrVo3evXurnLDyOnDgAPPmzcPT05OgoCC14xjJyMjA3Ny82IWuO3fuBIrPXlSRpk2bRk5OjtFYTEwMmzZtYtq0aaofTMvIyKBevXpGbSz5+fmsXbuWOnXqqLptbtmyJQ4ODkRERDB27FhDC/WBAwfIyckpsxnupJhXSYcOHfDw8GDx4sWkpqbStGlTwsPDuXfvHgsXLlQ7HgArV64EMMzdvnfvXs6cOUO9evXw8fFRLdeiRYs4evQoPXv2JCMjg7179xoeq1OnDu7u7qplAwgMDKRmzZp07NgRGxsb7t+/z+7du0lOTla9ODA3Ny9x/WzYsIHq1auruu4CAwOpXbs2HTt2xMrKimvXrrF9+3asrKwICAhQLVeRtm3bMmDAANasWcPDhw9p06YNx48fJyoqiilTplSKI7gHDhzgyZMnlarFBsDPz48TJ04wfPhwPv74YywsLPjpp584ceIEw4YNU/UL7smTJ1mzZg3du3fH0tKSc+fOER4ejqenJ/369avwPKXZ7k6dOpVx48bh5+dH3759SUhIYMuWLXh5eZXrrE+lyXb06FFD25ROpyM+Pt7wuv79+xeb672issXFxTF16lQsLS3p1q0b+/btM3p99+7dy/Vuv6/Kd/ToUVatWsX7779P06ZNefz4MVFRUURFRfGnP/2pXKc1flW2rl27FntNUXtIly5dyv1sUGnW3erVq+nTpw+2trZkZGQQHh7OrVu3mD17drle91Kaz0RQUBBjxozB29ub/v37k5qayoYNG2jTpg0ffvhhmeQwUSrzXU/+4PLz81m6dCkRERFkZmai0Wj4+9//jqurq9rRAF54tMzW1tZoermKNmLECH755ZcSH1M7G8CuXbvYu3cviYmJZGVlYW5ubphX1sXFRdVsLzJixAiysrKMvhhVtI0bNxIREcHt27fJycnB2tqaHj16EBAQQOPGjVXL9SydTsfKlSvZs2cPaWlp2NnZ4evrW2lmePDy8uLOnTv85z//UX0qu+fFxcUREhLClStXyMjIwNbWlkGDBuHn56dq1lu3bjFnzhwuX75Mbm4uzZs3Z8iQIfj4+KhyQX1pt7tHjhwhNDSU69evY21tzaBBg/j000/L9QLF0mQLCgoiPDy8xOdt3LiRLl26qJJt9+7dL52AoDyzwavzJSQksGbNGs6ePUtaWhrVqlXD3t4eT09PRowYUeLsdxWVrSRF63PPnj3lXsy/Kt/FixcJDQ3l8uXLpKen8z//8z84OjoyevRoevbsqWq2IidOnCAkJIT4+HjMzMxwc3Nj8uTJZdZCKsW8EEIIIYQQVZTMZiOEEEIIIUQVJcW8EEIIIYQQVZQU80IIIYQQQlRRUswLIYQQQghRRUkxL4QQQgghRBUlxbwQQgghhBBVlBTzQgghhBBCVFFSzAshhFBVUlISGo2GkJAQtaMIIUSVI8W8EEL8wZ06dQqNRmP0r127dri5uTFt2jTDrch/r5CQEI4cOVJGacvO4cOH0Wg0pKSkAHDgwAFatWpluBW9EEL8EZTffZ+FEEJUKh988AHvvvsuAPn5+cTHx7Nz504OHjxIREQEtra2v+vnhoaGMnDgQNzd3csy7v9ZbGwsdnZ2NGzYEIAzZ87w1ltvUa9ePZWTCSFE2ZFiXgghXhNt2rShf//+RmPNmjVj/vz5HD58GF9fX3WClZOzZ8/SqVMnw/KZM2fo2LGjiomEEKLsSTEvhBCvsQYNGgBgampqNL5lyxYiIyO5du0ajx49wtLSkq5duxIYGIidnR3wtNfdzc0NgPDwcMLDww2vj4+PN/w/JiaGdevWcf78ebRaLQ0aNKBLly5MnjwZa2tro/c9duwYoaGhJCQkYGFhgaenJ5MmTaJGjVfvrgoKCsjOzgagsLCQS5cu4ebmRnp6Onl5eSQkJPDRRx+Rnp4OgKWlJdWqSbepEKJqM1EURVE7hBBCiPJz6tQpRo4cSUBAAN7e3sDTNpuEhAQWLFhAZmYmERER2NjYGF7j5uaGk5MTGo0GS0tLEhIS2LVrF3Xr1iUiIgIrKyu0Wi2HDx9m6tSpdO7cmaFDhxpeX3QGYNu2bcyePZuGDRsyYMAAbG1tuXfvHseOHWPRokW0bt3a8KWgXbt23L17l2HDhmFjY0NkZCRRUVFMnDiRsWPHlvr3LK3IyEjDFxMhhKiqpJgXQog/uJcVuW+99RbLly+nZcuWRuNarRYzMzOjsZMnT+Lr68vkyZMZM2aMYVyj0TBw4EAWLVpk9Pzk5GTc3d1p2rQp27ZtK9arrtfrqVatmqGYr127Nvv37zcU2Iqi4OnpSUZGBlFRUa/8PTMzM7l06RIAO3bs4JdffmHx4sUAbN26lUuXLjF//nzD852dnalZs+Yrf64QQlRm0mYjhBCvCS8vLzw8PICnR+YTExNZv349/v7+bNy40egC2KJCXq/Xk5ubS0FBARqNBnNzc+Li4kr1fj/++CMFBQV89tlnJV50+nyLi5ubm9GRchMTE7p06cLmzZvJzc2lTp06L30/CwsLXF1dAVi2bBmurq6G5a+++ooePXoYloUQ4o9CinkhhHhNNGvWzKiY7dmzJy4uLgwdOpTFixfzr3/9y/DYyZMnWblyJefPnyc/P9/o52RmZpbq/W7dugVA69atS/X8Jk2aFBuztLQEICMj46XF/LP98rm5uVy4cAFPT0/S09PJzs7mypUreHt7G/rln+/VF0KIqkqKeSGEeI116NABc3NzYmJiDGNxcXH4+fnRtGlTJk2ahJ2dHbVq1cLExISJEydSXt2Z1atXf+Fjr3rP2NjYYq1Ec+fOZe7cuYblGTNmMGPGDMD4Al0hhKjKpJgXQojXXGFhITqdzrC8f/9+CgsLCQsLMzpartVqf9MNl5o3bw7AlStXsLe3L7O8JWnVqhXr168HYPPmzSQkJDBnzhwA1q5dy71795g5c2a5ZhBCCDXInFxCCPEai46ORqvV4ujoaBh70RHyNWvWoNfri42bmZmRkZFRbNzDwwNTU1NWrFhBTk5OscfL8gh/Ub+8q6srDx48oGvXrobl5ORkw/+f7aMXQog/AjkyL4QQr4nLly+zd+9eAHQ6HYmJiezYsQNTU1MCAwMNz3N3d+ebb75hzJgxeHl5YWpqSnR0NPHx8VhZWRX7uU5OTpw8eZJ///vfNG7cGBMTE/r160ejRo2YPn06c+bMwdPTk/79+2Nra0tKSgqRkZEsWLCg1P30pZWTk8Ply5fx8fEBID09nevXr/PZZ5+V6fsIIURlIcW8EEK8Jvbv38/+/fuBpzPJWFpa0r17d/z9/Wnfvr3hec7OzoSEhLBy5UqWLVtGzZo1cXV1ZfPmzYYi+VmzZs1izpw5rF69mtzcXAD69esHgLe3N02bNmXt2rVs2rQJnU5HgwYN6NatG40aNSrz3zE2NpbCwkLeeecd4OldXxVFMSwLIcQfjcwzL4QQQgghRBUlPfNCCCGEEEJUUVLMCyGEEEIIUUVJMS+EEEIIIUQVJcW8EEIIIYQQVZQU80IIIYQQQlRRUswLIYQQQghRRUkxL4QQQgghRBUlxbwQQgghhBBVlBTzQgghhBBCVFFSzAshhBBCCFFF/T9pRH+UhjKi+AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0a0mxRbCyx-"
      },
      "source": [
        "Combine the results fro all batches and calculate the final MCC score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qbsG9wuCyZU",
        "outputId": "982aa82c-438e-4701-b2d7-d1659fa7fdb7"
      },
      "source": [
        "# Combine the results across all batches. \r\n",
        "flat_predictions = np.concatenate(predictions, axis=0)\r\n",
        "\r\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\r\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\r\n",
        "\r\n",
        "# Combine the correct labels for each batch into a single list.\r\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\r\n",
        "\r\n",
        "# Calculate the MCC\r\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\r\n",
        "\r\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4hXqq5jHZWJ"
      },
      "source": [
        "### Appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-VuF_I2HdpR"
      },
      "source": [
        "Save the model in colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9fvwGMiCddx",
        "outputId": "9a969d2f-ff5c-4b53-9199-b3c7f585a752"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\r\n",
        "\r\n",
        "output_dir = './model_save/'\r\n",
        "\r\n",
        "# Create output directory if needed\r\n",
        "if not os.path.exists(output_dir):\r\n",
        "    os.makedirs(output_dir)\r\n",
        "\r\n",
        "print(\"Saving model to %s\" % output_dir)\r\n",
        "\r\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\r\n",
        "# They can then be reloaded using `from_pretrained()`\r\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\r\n",
        "model_to_save.save_pretrained(output_dir)\r\n",
        "tokenizer.save_pretrained(output_dir)\r\n",
        "\r\n",
        "# Good practice: save your training arguments together with the trained model\r\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/tokenizer_config.json',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/vocab.txt',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UqHC11lHnvj"
      },
      "source": [
        "Save the model to google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzoPlhp2Hs9E",
        "outputId": "e6b9fac1-1a1e-49f7-b82e-4e568fab4db8"
      },
      "source": [
        "# Mount Google Drive to this Notebook instance.\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6kV6D3BHtzu"
      },
      "source": [
        "# Copy the model files to a directory in your Google Drive.\r\n",
        "!cp -r './model_save/' \"./drive/MyDrive/Google Colab Files/BERT Fine-Tuning/\""
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzY_fd_ZKnKK"
      },
      "source": [
        "The huggingface example includes the following code block for enabling weight decay, but the default decay rate is \"0.0\", so I moved this to the appendix.\r\n",
        "\r\n",
        "This block essentially tells the optimizer to not apply weight decay to the bias terms (e.g., $ b $ in the equation $ y = Wx + b $ ). Weight decay is a form of regularization--after calculating the gradients, we multiply them by, e.g., 0.99."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "UM6q1UmTJKA1",
        "outputId": "9480a2b3-07c0-450b-d9df-abd5699e0db3"
      },
      "source": [
        "# This code is taken from:\r\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L102\r\n",
        "\r\n",
        "# Don't apply weight decay to any parameters whose names include these tokens.\r\n",
        "# (Here, the BERT doesn't have `gamma` or `beta` parameters, only `bias` terms)\r\n",
        "no_decay = ['bias', 'LayerNorm.weight']\r\n",
        "\r\n",
        "# Separate the `weight` parameters from the `bias` parameters. \r\n",
        "# - For the `weight` parameters, this specifies a 'weight_decay_rate' of 0.01. \r\n",
        "# - For the `bias` parameters, the 'weight_decay_rate' is 0.0. \r\n",
        "optimizer_grouped_parameters = [\r\n",
        "    # Filter for all parameters which *don't* include 'bias', 'gamma', 'beta'.\r\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\r\n",
        "     'weight_decay_rate': 0.1},\r\n",
        "    \r\n",
        "    # Filter for parameters which *do* include those.\r\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\r\n",
        "     'weight_decay_rate': 0.0}\r\n",
        "]\r\n",
        "\r\n",
        "# Note - `optimizer_grouped_parameters` only includes the parameter values, not \r\n",
        "# the names."
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-b5ff1419cc87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m optimizer_grouped_parameters = [\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Filter for all parameters which *don't* include 'bias', 'gamma', 'beta'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n\u001b[0m\u001b[1;32m     14\u001b[0m      'weight_decay_rate': 0.1},\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'param_optimizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1VdAXenKuN0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}