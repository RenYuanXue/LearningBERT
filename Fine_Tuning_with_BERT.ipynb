{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine Tuning with BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LHYAtRIIwy_4"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN/lufX8EW0IjE88kYowWds",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ccfc8e35ef0146d5a1b5fa2acf3d8e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1120d10f6e53403c83d295924bff3f08",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fd7ba25f87bb4634b4a34503dcde029e",
              "IPY_MODEL_d1d10bb83862408a883f8ef37625180d"
            ]
          }
        },
        "1120d10f6e53403c83d295924bff3f08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd7ba25f87bb4634b4a34503dcde029e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f829219de7da4ad7b0162ad091f1776d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24304836436744db853937a61e2bee16"
          }
        },
        "d1d10bb83862408a883f8ef37625180d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_23b03d7c8616494c9c59d8a19cf87fae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 2.27MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b33211ff342e4e11bfd9164b52aa5784"
          }
        },
        "f829219de7da4ad7b0162ad091f1776d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24304836436744db853937a61e2bee16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23b03d7c8616494c9c59d8a19cf87fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b33211ff342e4e11bfd9164b52aa5784": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RenYuanXue/LearningBERT/blob/main/Fine_Tuning_with_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHYAtRIIwy_4"
      },
      "source": [
        "## Load CoLA Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d99IYJpixEoX"
      },
      "source": [
        "Get wget package to download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeR11_5Gw1M5",
        "outputId": "08082c16-7c1a-4d43-9ba3-abdb66df2c79"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=2d7c73634b8af408de9ac83ce1610d3e3fd3f56f493b06b8ffd7e19ba522c212\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUMNb6FNxQO1"
      },
      "source": [
        "Download the zip file using wget"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm4bvatVw8hQ",
        "outputId": "6d43aa67-020e-4714-c461-609709bb2fbc"
      },
      "source": [
        "import wget\r\n",
        "import os\r\n",
        "\r\n",
        "print('Downloading dataset...')\r\n",
        "\r\n",
        "# The url for the dataset zip file.\r\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\r\n",
        "\r\n",
        "# Download the file (if we haven't already)\r\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\r\n",
        "  wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y73UXqHnyZED"
      },
      "source": [
        "Unzip the dataset to file system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlaHyyC-yb8v",
        "outputId": "c1cea0dd-3bb7-4f89-e10c-78ce7a952960"
      },
      "source": [
        "# Unzip the dataset (if we haven't done so).\r\n",
        "if not os.path.exists('./cola_public/'):\r\n",
        "  !unzip cola_public_1.1.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxES8m_YzldW"
      },
      "source": [
        "Load the dataset to pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "pVOjFg88ym-M",
        "outputId": "03e4c840-44e5-4559-d40c-b838da49c8af"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "# Load data to pandas dataframe.\r\n",
        "df = pd.read_csv('./cola_public/raw/in_domain_train.tsv',\r\n",
        "          delimiter = '\\t', header = None,\r\n",
        "          names = ['sentence_source', 'label', 'label_notes', 'sentence'])\r\n",
        "\r\n",
        "# Report number of sentences in the dataframe.\r\n",
        "print('Number of training sentences: {0}'.format(df.shape[0]))\r\n",
        "\r\n",
        "# Display first few rows from the data.\r\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 8551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our friends won't buy this analysis, let alone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One more pseudo generalization and I'm giving up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One more pseudo generalization or I'm giving up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The more we study verbs, the crazier they get.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Day by day the facts are getting murkier.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentence_source  ...                                           sentence\n",
              "0            gj04  ...  Our friends won't buy this analysis, let alone...\n",
              "1            gj04  ...  One more pseudo generalization and I'm giving up.\n",
              "2            gj04  ...   One more pseudo generalization or I'm giving up.\n",
              "3            gj04  ...     The more we study verbs, the crazier they get.\n",
              "4            gj04  ...          Day by day the facts are getting murkier.\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLraAF-c0yo_"
      },
      "source": [
        "If the sentence is grammatically correct, it is labelled as 1, otherwise 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKHZJ-xn1Ci6"
      },
      "source": [
        "Extract the sentences and labels used for BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZdK--Nbz62v"
      },
      "source": [
        "sentences = df.sentence.values\r\n",
        "labels = df.label.values"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVtVRS971PFX"
      },
      "source": [
        "## Tokenization & input formatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QawUCnoU27DU"
      },
      "source": [
        "Get transformers library in case don't have it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YPB1Y7c3EAe",
        "outputId": "9bf87fdf-a8b3-4cc6-f40f-f1e1b15557be"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.9MB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.2MB 41.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=860afb29ee5d45b645b1dcc6d81cbe1963f6c1c8a553790af89313854b958dc7\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7pki19Z2twm"
      },
      "source": [
        "First, we need to load the BERT tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ccfc8e35ef0146d5a1b5fa2acf3d8e05",
            "1120d10f6e53403c83d295924bff3f08",
            "fd7ba25f87bb4634b4a34503dcde029e",
            "d1d10bb83862408a883f8ef37625180d",
            "f829219de7da4ad7b0162ad091f1776d",
            "24304836436744db853937a61e2bee16",
            "23b03d7c8616494c9c59d8a19cf87fae",
            "b33211ff342e4e11bfd9164b52aa5784"
          ]
        },
        "id": "fng1CMjx1KtD",
        "outputId": "cac25a86-df14-4b74-fb2f-e1b6f9e49722"
      },
      "source": [
        "from transformers import BertTokenizer\r\n",
        "\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccfc8e35ef0146d5a1b5fa2acf3d8e05",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CjxxPCq3LxD"
      },
      "source": [
        "Apply the tokenizer to our input sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyUb0KMO3RWq",
        "outputId": "30672e37-78cd-4b37-9d6a-ea5f3cabd2a9"
      },
      "source": [
        "# Print original sentence.\r\n",
        "print('Original: ', sentences[0])\r\n",
        "\r\n",
        "# Print splitted sentences as tokens.\r\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\r\n",
        "\r\n",
        "# Print sentences mapped to token ids.\r\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soiP79AFNWll"
      },
      "source": [
        "Use tokenizer encode function to encode sentences. However, it only takes care of truncating, not padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTgVWRGJ36t-"
      },
      "source": [
        "# Save mapped sentences.\r\n",
        "input_ids = []\r\n",
        "\r\n",
        "# Loop through all sentences.\r\n",
        "for sentence in sentences:\r\n",
        "  # The function encode will:\r\n",
        "  # 1. Map each word to corresponded ids.\r\n",
        "  # 2. Append [SEP] at end of each sentence.\r\n",
        "  # 3. Prepand [CLS] to start of each sentence.\r\n",
        "  # 4. Map tokens to their IDs.\r\n",
        "  encoded_sentence = tokenizer.encode(\r\n",
        "              sentence,\r\n",
        "              add_special_tokens = True # Add [SEP] and [CLS]\r\n",
        "              # max_length = 128, # Truncate all sentences.\r\n",
        "              # return_tensors = 'pt' # Return pytorch tensors.\r\n",
        "            )\r\n",
        "  input_ids.append(encoded_sentence)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmtC6pfWPAfS"
      },
      "source": [
        "Now we need to padding and truncating. Find the maximum sentence length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sVt5vybO5G5",
        "outputId": "f3a5833e-53b5-4b7c-e6ed-b56b00531d42"
      },
      "source": [
        "print('Max sentence length: {0}'.format(max([len(sentence) for sentence in input_ids])))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length: 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57zIfsLNPZXq"
      },
      "source": [
        "Therefore we choose max_length = 64, since 32 < 47 < 64."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGnr-vThPVWc"
      },
      "source": [
        "# Use Keras to do the padding.\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "MAX_LEN = 64\r\n",
        "\r\n",
        "input_ids = pad_sequences(input_ids, maxlen = MAX_LEN, dtype = \"long\",\r\n",
        "              value = 0, truncating = 'post', padding = 'post')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGT2fgOXQHvP"
      },
      "source": [
        "Now, create attention masks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrZnxkkRP4yz"
      },
      "source": [
        "attention_masks = []\r\n",
        "\r\n",
        "for sentence in input_ids:\r\n",
        "  curr_mask = [int(token_id > 0) for token_id in sentence]\r\n",
        "\r\n",
        "  attention_masks.append(curr_mask)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbFTfqvsCIcj"
      },
      "source": [
        "Make train and validation splits using sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "rXbgGCYLQbg1",
        "outputId": "f38e021f-d922-4ea3-eb3e-ecf692de59bf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "# 90% Train, 10% Validation.\r\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,\r\n",
        "                                            random_state = 2018, test_size = 0.1)\r\n",
        "\r\n",
        "# Do the same for masking.\r\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\r\n",
        "                              random_state = 2018, test_size = 0.1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-053b24d077ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 90% Train, 10% Validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,\n\u001b[0m\u001b[1;32m      5\u001b[0m                                             random_state = 2018, test_size = 0.1)\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_ids' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaV54KZKDGTH"
      },
      "source": [
        "Now, convert all used inputs to torch tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "DFNQqulfDCtS",
        "outputId": "c5cb07cf-555a-4252-a134-8e91d6e71333"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\r\n",
        "validation_inputs = torch.tensor(validation_inputs)\r\n",
        "\r\n",
        "train_labels = torch.tensor(train_labels)\r\n",
        "validation_inputs = torch.tensor(validation_inputs)\r\n",
        "\r\n",
        "train_masks = torch.tensor(train_masks)\r\n",
        "validation_inputs = torch.tesnor(validation_masks)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-10fac190455f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalidation_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalidation_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdULSfNgDmR1"
      },
      "source": [
        "Lastly, we use torch's DataLoader to make batches of inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnStrhjdDixj"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n",
        "\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# Create DataLoader for training set.\r\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\r\n",
        "train_sampler = RandomSampler(train_data)\r\n",
        "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\r\n",
        "\r\n",
        "# Create DataLoader for validation set.\r\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\r\n",
        "validation_sampler = RandomSampler(validation_data)\r\n",
        "validation_dataloader = DataLoader(validation_data, sampler = validation_sampler, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}