{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "inspect-bert-vocabulary.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCu2Azv9as5j"
      },
      "source": [
        "# Get BERT Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8l14GwXmas5k",
        "outputId": "11951831-6068-48f5-83cc-fb5e8ca937ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 11.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 11.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.19.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.7.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/34/b9cebec0198a40cebc0b9df8580f1f5d6d2b08edbde5a9e4300c84ba5d61/boto3-1.17.14-py2.py3-none-any.whl (130kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 13.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/43/4b4a1b26eb03a429a4c37ca7fdf369d938bd60018fc194e94b8379b0c77c/s3transfer-0.3.4-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.5MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/26/239d5615b9fcad77c67d2657b62c149ebb536a77d96a1cb72b040449a2cf/botocore-1.20.14-py2.py3-none-any.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 16.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.14->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.14->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "\u001b[31mERROR: botocore 1.20.14 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "Successfully installed boto3-1.17.14 botocore-1.20.14 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.3.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fWWBezYas5k"
      },
      "source": [
        "# Get all vocabularies in base BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lAasibCRas5k",
        "outputId": "640c2d02-3e08-44b4-a45e-ebf881020d09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 681837.92B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz2ONRAMas5k"
      },
      "source": [
        "# Write all tokens to local file \"vocabulary.txt\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vfyH9bEVas5l"
      },
      "source": [
        "with open('vocabulary.txt', 'w') as f:\n",
        "    \n",
        "    # For each token.\n",
        "    for token in tokenizer.vocab.keys():\n",
        "            \n",
        "        # Write it out and escape any unicode characters.\n",
        "        f.write(token + '\\n')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ4t_hhlas5l"
      },
      "source": [
        "# Analysis on BERT vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkgC2Lkkas5l"
      },
      "source": [
        "### 1). Any misspelled words?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3XsGK_u1as5l",
        "outputId": "6b75c7e1-66c1-4427-d263-0142eb892825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('misspelled' in tokenizer.vocab)\n",
        "print('destory' in tokenizer.vocab)\n",
        "print('governament' in tokenizer.vocab)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wrn-PhhJas5m"
      },
      "source": [
        "### **Seems like there is no mispelled words in BERT vocabulary.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ciTvsCsas5m"
      },
      "source": [
        "### 2). How contraction works?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6BaeOwilas5m",
        "outputId": "555c4849-622b-4f07-e779-36a1d41988fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"can't\" in tokenizer.vocab)\n",
        "print('cant' in tokenizer.vocab)\n",
        "print('cannot' in tokenizer.vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMYY_ZJ9as5m"
      },
      "source": [
        "### Seems like the words spelled fully in the vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfvqlBMBas5m"
      },
      "source": [
        "### 3). Check any words that only has ## in front, not itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5AW0tRSXas5n",
        "outputId": "eec79cb4-9dcd-4cb9-caf6-9e5c634dbe37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "count = 0\n",
        "# For each token.\n",
        "for token in tokenizer.vocab:\n",
        "  if len(token) > 2 and token[:2] == '##':\n",
        "    if token[2:] in tokenizer.vocab:\n",
        "      continue\n",
        "    elif count < 10:\n",
        "      count += 1\n",
        "      print('Word {0} is not in vocabulary'.format(token[2:]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word ly is not in vocabulary\n",
            "Word ers is not in vocabulary\n",
            "Word ism is not in vocabulary\n",
            "Word ity is not in vocabulary\n",
            "Word ies is not in vocabulary\n",
            "Word ine is not in vocabulary\n",
            "Word ey is not in vocabulary\n",
            "Word ation is not in vocabulary\n",
            "Word ble is not in vocabulary\n",
            "Word tion is not in vocabulary\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfftcfDnas5n"
      },
      "source": [
        "### A number of subwords doesn't have itself in the vocabulary."
      ]
    }
  ]
}